# 파이썬 활용 사례 모음

> 💡 **Python으로 실제로 만들 수 있는 것들**
>
> 이 문서는 Python 초급자들이 참고할 수 있는 실전 활용 사례 모음입니다.
> 각 예시는 완전한 코드와 설명을 포함하고 있습니다.

**🔗 관련 노트**: [공개 데이터셋 모음](%EA%B3%B5%EA%B0%9C%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%85%8B%20%EB%AA%A8%EC%9D%8C.md) - 실습용 데이터가 필요하면 여기를 참고하세요!

---

# 📊 데이터 & 업무 자동화

## 1. 엑셀 파일 자동 처리

**📝 설명**: 여러 엑셀 파일을 읽어서 데이터를 필터링하고 새 파일로 저장합니다.

**🔧 필요한 라이브러리**:
```bash
pip install pandas openpyxl xlwings
```

### 방법 1: pandas 사용 (데이터 처리에 최적)

**💻 코드**:
```python
import pandas as pd
import numpy as np
import os

# 📌 실습용 샘플 엑셀 파일 생성
os.makedirs("data", exist_ok=True)

for month in range(1, 4):
    df = pd.DataFrame({
        '날짜': pd.date_range(f'2024-{month:02d}-01', periods=30),
        '제품': np.random.choice(['노트북', '마우스', '키보드', '모니터'], 30),
        '금액': np.random.randint(10000, 500000, 30)
    })
    df.to_excel(f"data/{month}월.xlsx", index=False, engine='openpyxl')

print("✅ 샘플 엑셀 파일 생성 완료!")

# 여러 엑셀 파일 읽기
files = ["data/1월.xlsx", "data/2월.xlsx", "data/3월.xlsx"]
all_data = pd.concat([pd.read_excel(f) for f in files])

# 데이터 필터링 (예: 금액이 10000 이상인 항목만)
filtered = all_data[all_data["금액"] >= 10000]

# 합계 계산
total = filtered["금액"].sum()
print(f"총 합계: {total:,}원")

# 새 파일로 저장
filtered.to_excel("1분기_통합_10000이상.xlsx", index=False)
print("✅ 파일 저장 완료!")
```

### 방법 2: xlwings 사용 (Excel 기능 활용 & 자동화)

**📝 설명**: xlwings는 실제 Excel을 제어하여 수식, 서식, 매크로 등을 활용할 수 있습니다.

**💻 코드**:
```python
import xlwings as xw
import pandas as pd

# Excel 앱 실행 (보이지 않게)
app = xw.App(visible=False)

try:
    # 여러 시트를 하나의 워크북으로 통합
    wb = app.books.add()
    summary_sheet = wb.sheets[0]
    summary_sheet.name = "통합데이터"

    # 여러 파일에서 데이터 가져오기
    files = ["1월.xlsx", "2월.xlsx", "3월.xlsx"]
    all_data = []

    for file in files:
        df = pd.read_excel(file)
        all_data.append(df)

    # 데이터 통합
    combined = pd.concat(all_data, ignore_index=True)

    # 엑셀에 데이터 쓰기
    summary_sheet.range('A1').value = combined

    # 헤더 스타일 적용
    header_range = summary_sheet.range('A1').expand('right')
    header_range.color = (68, 114, 196)  # 파란색 배경
    header_range.api.Font.Color = 0xFFFFFF  # 흰색 글자
    header_range.api.Font.Bold = True

    # 자동 필터 적용
    summary_sheet.range('A1').api.AutoFilter(1)

    # 합계 수식 추가 (예: D열이 금액이라고 가정)
    last_row = len(combined) + 1
    summary_sheet.range(f'D{last_row + 2}').value = '=SUM(D2:D' + str(last_row) + ')'
    summary_sheet.range(f'D{last_row + 2}').api.Font.Bold = True

    # 저장
    wb.save("1분기_통합_xlwings.xlsx")
    wb.close()

    print("✅ xlwings로 파일 생성 완료!")

finally:
    app.quit()
```

### 방법 3: xlwings로 새 워크북 생성 및 차트 추가

**📝 설명**: xlwings로 새 워크북을 만들고, 랜덤 데이터를 채우고, 차트를 추가합니다.

**💻 코드**:
```python
import xlwings as xw
import random
from datetime import datetime, timedelta

# Excel 앱 실행
app = xw.App(visible=True)

try:
    # 새 워크북 생성
    wb = app.books.add()
    sheet = wb.sheets[0]
    sheet.name = "판매데이터"

    # 헤더 작성 (5개 컬럼)
    headers = ['날짜', '제품명', '판매량', '단가', '총액']
    sheet.range('A1').value = headers

    # 헤더 스타일 적용
    header_range = sheet.range('A1:E1')
    header_range.color = (68, 114, 196)  # 파란색 배경
    header_range.api.Font.Color = 0xFFFFFF  # 흰색 글자
    header_range.api.Font.Bold = True

    # 랜덤 데이터 생성 (10개 행)
    products = ['노트북', '마우스', '키보드', '모니터', '스피커']
    start_date = datetime(2025, 1, 1)

    data = []
    for i in range(10):
        date = start_date + timedelta(days=i)
        product = random.choice(products)
        quantity = random.randint(5, 50)
        price = random.randint(10000, 500000)
        total = quantity * price

        data.append([
            date.strftime('%Y-%m-%d'),
            product,
            quantity,
            price,
            total
        ])

    # 데이터 쓰기
    sheet.range('A2').value = data

    # 숫자 포맷 적용
    sheet.range('C2:E11').number_format = '#,#'

    # 열 너비 자동 조정
    sheet.autofit()

    # 차트 생성 (제품별 총액 막대 그래프)
    chart = sheet.charts.add()
    chart.set_source_data(sheet.range('B1:B11,E1:E11'))  # 제품명과 총액
    chart.chart_type = 'column_clustered'
    chart.name = '제품별 판매액'

    # 차트 위치 설정
    chart.left = sheet.range('G2').left
    chart.top = sheet.range('G2').top
    chart.width = 400
    chart.height = 300

    # 저장
    save_path = "판매데이터_차트.xlsx"
    wb.save(save_path)

    print(f"✅ 워크북 생성 완료: {save_path}")
    print(f"   - 5개 컬럼, 10개 데이터 행")
    print(f"   - 제품별 판매액 차트 추가됨")

except Exception as e:
    print(f"❌ 에러 발생: {e}")

finally:
    # Excel 앱은 종료하지 않고 파일만 유지 (사용자가 확인할 수 있도록)
    print("\n💡 Excel 파일이 열려있습니다. 확인 후 직접 닫아주세요.")
```

**🎯 활용 시나리오**:
- 월별 매출 데이터 통합
- 여러 부서의 예산 데이터 합치기
- 조건에 맞는 데이터만 추출하여 보고서 작성
- **기존 Excel 서식과 수식을 유지하면서 자동화** (xlwings 특화)
- **Excel VBA 매크로를 Python으로 대체** (xlwings 특화)

**💡 확장 아이디어**:
- 자동으로 그래프 생성하여 엑셀에 삽입
- 이메일로 자동 발송
- 매일 자동 실행되도록 스케줄링
- Excel 템플릿에 데이터만 자동으로 채우기 (xlwings)
- 피벗 테이블 자동 생성 (xlwings)

**📚 pandas vs xlwings 선택 가이드**:
- **pandas**: 대용량 데이터 분석, 빠른 처리 속도, CSV/DB 연동
- **xlwings**: Excel 서식 유지, 수식 활용, 매크로 대체, 사용자 친화적

---

## 2. 여러 CSV 파일 병합 및 중복 제거

**📝 설명**: 폴더 내 모든 CSV 파일을 하나로 합치고 중복 행을 제거합니다.

**🔧 필요한 라이브러리**:
```bash
pip install pandas
```

**💻 전체 코드**:
```python
import pandas as pd
import numpy as np
import glob
import os

# 📌 실습용 샘플 CSV 파일 생성
os.makedirs("data", exist_ok=True)

for i in range(1, 4):
    df = pd.DataFrame({
        '이름': np.random.choice(['김철수', '이영희', '박민수', '최지은'], 30),
        '날짜': pd.date_range(f'2024-{i:02d}-01', periods=30),
        '점수': np.random.randint(60, 100, 30)
    })
    df.to_csv(f"data/test_{i}.csv", index=False, encoding='utf-8-sig')

print("✅ 샘플 CSV 파일 생성 완료!")

# 특정 폴더의 모든 CSV 파일 찾기
csv_files = glob.glob("data/test_*.csv")
print(f"찾은 파일: {len(csv_files)}개")

# 모든 CSV 파일 읽어서 합치기
dataframes = []
for file in csv_files:
    df = pd.read_csv(file)
    dataframes.append(df)

# 하나의 데이터프레임으로 합치기
combined = pd.concat(dataframes, ignore_index=True)
print(f"전체 행 수: {len(combined)}")

# 중복 제거
combined_unique = combined.drop_duplicates()
print(f"중복 제거 후: {len(combined_unique)}행")

# 저장
combined_unique.to_csv("combined_unique.csv", index=False, encoding="utf-8-sig")
print("✅ 병합 완료!")
```

**🎯 활용 시나리오**:
- 여러 지점의 판매 데이터 통합
- 로그 파일 병합 및 분석
- 설문조사 결과 통합

**💡 확장 아이디어**:
- 특정 열을 기준으로 중복 제거 (`drop_duplicates(subset=['이름', '날짜'])`)
- 병합하면서 데이터 검증 추가
- 진행률 표시 (tqdm 라이브러리 사용)

---

## 3. 데이터 시각화 대시보드

**📝 설명**: 데이터를 읽어서 다양한 차트를 자동으로 생성합니다.

**🔧 필요한 라이브러리**:
```bash
pip install pandas matplotlib seaborn openpyxl
```

**💻 전체 코드**:
```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# 한글 폰트 설정
plt.rcParams['font.family'] = 'AppleGothic'  # Mac
# plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows

# 📌 실습용 샘플 데이터 생성
np.random.seed(42)
months = []
products = []
sales = []
regions = []

for month in range(1, 13):
    for _ in range(50):
        months.append(month)
        products.append(np.random.choice(['노트북', '마우스', '키보드', '모니터', '헤드셋']))
        sales.append(np.random.randint(10000, 500000))
        regions.append(np.random.choice(['서울', '부산', '대구', '인천']))

df = pd.DataFrame({
    '월': months,
    '제품': products,
    '매출': sales,
    '지역': regions
})

print("✅ 샘플 데이터 생성 완료!")
print(f"데이터 크기: {len(df)}행")

# 서브플롯 생성 (2x2 그리드)
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('매출 대시보드', fontsize=16, fontweight='bold')

# 1. 월별 매출 추이 (꺾은선 그래프)
monthly = df.groupby('월')['매출'].sum()
axes[0, 0].plot(monthly.index, monthly.values, marker='o', linewidth=2)
axes[0, 0].set_title('월별 매출 추이')
axes[0, 0].set_xlabel('월')
axes[0, 0].set_ylabel('매출 (원)')
axes[0, 0].grid(True, alpha=0.3)

# 2. 제품별 매출 (막대 그래프)
product_sales = df.groupby('제품')['매출'].sum().sort_values(ascending=False).head(5)
axes[0, 1].bar(product_sales.index, product_sales.values, color='skyblue')
axes[0, 1].set_title('Top 5 제품 매출')
axes[0, 1].set_xlabel('제품')
axes[0, 1].set_ylabel('매출 (원)')
axes[0, 1].tick_params(axis='x', rotation=45)

# 3. 지역별 매출 비율 (파이 차트)
region_sales = df.groupby('지역')['매출'].sum()
axes[1, 0].pie(region_sales.values, labels=region_sales.index, autopct='%1.1f%%')
axes[1, 0].set_title('지역별 매출 비율')

# 4. 매출 분포 (히스토그램)
axes[1, 1].hist(df['매출'], bins=30, color='lightgreen', edgecolor='black')
axes[1, 1].set_title('매출 분포')
axes[1, 1].set_xlabel('매출 (원)')
axes[1, 1].set_ylabel('빈도')

plt.tight_layout()
plt.savefig('sales_dashboard.png', dpi=300, bbox_inches='tight')
print("✅ 대시보드 이미지 저장 완료!")
plt.show()
```

**🎯 활용 시나리오**:
- 월간 매출 보고서 자동 생성
- 제품별 성과 분석
- 경영진 보고용 시각 자료

**💡 확장 아이디어**:
- 인터랙티브 차트 (plotly 사용)
- 자동으로 PPT에 삽입
- 웹 대시보드로 배포 (Streamlit 사용)

---

## 4. 이메일 자동 발송

**📝 설명**: 여러 수신자에게 맞춤형 이메일을 자동으로 발송합니다.

**🔧 필요한 라이브러리**:
```bash
pip install pandas
# smtplib, email 모듈은 Python 기본 라이브러리
```

**💻 전체 코드**:
```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import pandas as pd

def send_email(to_email, subject, body, attachment_path=None):
    """이메일 발송 함수"""

    # Gmail 설정
    sender_email = "your_email@gmail.com"
    sender_password = "your_app_password"  # Gmail 앱 비밀번호

    # 이메일 작성
    msg = MIMEMultipart()
    msg['From'] = sender_email
    msg['To'] = to_email
    msg['Subject'] = subject

    # 본문 추가
    msg.attach(MIMEText(body, 'plain'))

    # 첨부 파일 추가
    if attachment_path:
        with open(attachment_path, 'rb') as file:
            part = MIMEBase('application', 'octet-stream')
            part.set_payload(file.read())
            encoders.encode_base64(part)
            part.add_header('Content-Disposition', f'attachment; filename= {attachment_path}')
            msg.attach(part)

    # SMTP 서버 연결 및 발송
    try:
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()
        print(f"✅ {to_email}에게 이메일 발송 완료!")
        return True
    except Exception as e:
        print(f"❌ 이메일 발송 실패: {e}")
        return False

# 📌 실습용 샘플 수신자 데이터 생성
recipients = pd.DataFrame({
    '이름': ['김철수', '이영희', '박민수', '최지은', '정대성'],
    '이메일': ['kim@example.com', 'lee@example.com', 'park@example.com',
               'choi@example.com', 'jung@example.com']
})

# Excel로 저장 (선택사항)
recipients.to_excel("recipients.xlsx", index=False, engine='openpyxl')
print("✅ 샘플 수신자 데이터 생성 완료!")

# 각 수신자에게 이메일 발송
for idx, row in recipients.iterrows():
    name = row['이름']
    email = row['이메일']

    subject = f"{name}님께 드리는 월간 보고서"
    body = f"""
안녕하세요, {name}님!

이번 달 보고서를 첨부파일로 보내드립니다.

감사합니다.
    """

    send_email(email, subject, body, attachment_path="monthly_report.pdf")
```

**🎯 활용 시나리오**:
- 월간 보고서 자동 배포
- 고객 맞춤형 뉴스레터 발송
- 청구서 자동 발송

**💡 확장 아이디어**:
- HTML 이메일 템플릿 사용
- 발송 결과 로그 저장
- 실패 시 재시도 로직 추가

---

## 5. PDF 파일 처리 및 정보 추출

**📝 설명**: PDF 파일에서 텍스트를 추출하고 필요한 정보를 파싱합니다.

**🔧 필요한 라이브러리**:
```bash
pip install PyPDF2 pandas
```

**💻 전체 코드**:
```python
import PyPDF2
import re
import pandas as pd

def extract_text_from_pdf(pdf_path):
    """PDF에서 텍스트 추출"""
    text = ""
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

def extract_invoice_data(text):
    """청구서 정보 추출"""

    # 정규표현식으로 정보 추출
    invoice_number = re.search(r'Invoice #: (\d+)', text)
    date = re.search(r'Date: (\d{4}-\d{2}-\d{2})', text)
    total = re.search(r'Total: \$?([\d,]+\.?\d*)', text)

    return {
        '청구서번호': invoice_number.group(1) if invoice_number else None,
        '날짜': date.group(1) if date else None,
        '총액': total.group(1) if total else None
    }

# 여러 PDF 파일 처리
import glob

pdf_files = glob.glob("invoices/*.pdf")
results = []

for pdf_file in pdf_files:
    print(f"처리 중: {pdf_file}")
    text = extract_text_from_pdf(pdf_file)
    data = extract_invoice_data(text)
    data['파일명'] = pdf_file
    results.append(data)

# 데이터프레임으로 변환
df = pd.DataFrame(results)
print(df)

# 엑셀로 저장
df.to_excel("invoice_summary.xlsx", index=False)
print("✅ 청구서 정보 추출 완료!")
```

**🎯 활용 시나리오**:
- 청구서 자동 처리
- 계약서 정보 추출
- 영수증 데이터 정리

**💡 확장 아이디어**:
- OCR로 이미지 PDF도 처리 (pytesseract)
- 추출한 데이터 자동 검증
- 데이터베이스에 자동 저장

---

## 6. 파일 백업 자동화

**📝 설명**: 중요한 파일들을 자동으로 백업하고 압축합니다.

**💻 전체 코드**:
```python
import os
import shutil
import zipfile
from datetime import datetime
from pathlib import Path

def backup_directory(source_dir, backup_dir):
    """디렉토리 백업 함수"""

    # 백업 디렉토리 생성
    Path(backup_dir).mkdir(parents=True, exist_ok=True)

    # 타임스탬프로 백업 파일명 생성
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"backup_{timestamp}.zip"
    backup_path = os.path.join(backup_dir, backup_name)

    # ZIP 파일 생성
    print(f"백업 시작: {source_dir} → {backup_path}")

    with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(source_dir):
            for file in files:
                file_path = os.path.join(root, file)
                # 상대 경로로 추가
                arcname = os.path.relpath(file_path, source_dir)
                zipf.write(file_path, arcname)
                print(f"  추가: {arcname}")

    # 백업 파일 크기
    size_mb = os.path.getsize(backup_path) / (1024 * 1024)
    print(f"✅ 백업 완료! 크기: {size_mb:.2f} MB")

    return backup_path

def cleanup_old_backups(backup_dir, keep_count=5):
    """오래된 백업 파일 삭제"""

    # 백업 파일 목록 (날짜순 정렬)
    backups = sorted(
        [f for f in os.listdir(backup_dir) if f.startswith("backup_") and f.endswith(".zip")],
        reverse=True
    )

    # 오래된 백업 삭제
    if len(backups) > keep_count:
        for old_backup in backups[keep_count:]:
            old_path = os.path.join(backup_dir, old_backup)
            os.remove(old_path)
            print(f"🗑️  오래된 백업 삭제: {old_backup}")

# 백업 실행
source = "C:/Users/YourName/Documents/Important"
backup_location = "D:/Backups"

backup_path = backup_directory(source, backup_location)
cleanup_old_backups(backup_location, keep_count=5)
```

**🎯 활용 시나리오**:
- 중요 문서 정기 백업
- 프로젝트 파일 버전 관리
- 데이터베이스 백업

**💡 확장 아이디어**:
- 클라우드 스토리지에 자동 업로드 (AWS S3, Google Drive)
- 이메일로 백업 완료 알림
- 스케줄러로 매일 자동 실행

---

## 7. 이미지 일괄 처리 (리사이즈, 변환)

**📝 설명**: 폴더 내 모든 이미지를 일괄적으로 리사이즈하고 형식 변환합니다.

**🔧 필요한 라이브러리**:
```bash
pip install Pillow
```

**💻 전체 코드**:
```python
from PIL import Image
import os
from pathlib import Path

def batch_resize_images(input_dir, output_dir, max_width=800):
    """이미지 일괄 리사이즈"""

    # 출력 디렉토리 생성
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # 지원하는 이미지 확장자
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']

    # 이미지 파일 찾기
    image_files = [
        f for f in os.listdir(input_dir)
        if Path(f).suffix.lower() in image_extensions
    ]

    print(f"처리할 이미지: {len(image_files)}개")

    for idx, filename in enumerate(image_files, 1):
        input_path = os.path.join(input_dir, filename)

        # 이미지 열기
        with Image.open(input_path) as img:
            # 원본 크기
            original_width, original_height = img.size

            # 비율 유지하며 리사이즈
            if original_width > max_width:
                ratio = max_width / original_width
                new_height = int(original_height * ratio)
                img = img.resize((max_width, new_height), Image.Resampling.LANCZOS)

            # 파일명 생성 (PNG로 통일)
            name_without_ext = Path(filename).stem
            output_filename = f"{name_without_ext}.png"
            output_path = os.path.join(output_dir, output_filename)

            # 저장
            img.save(output_path, 'PNG', optimize=True)
            print(f"[{idx}/{len(image_files)}] {filename} → {output_filename}")

    print(f"✅ 총 {len(image_files)}개 이미지 처리 완료!")

# 실행
batch_resize_images(
    input_dir="원본이미지",
    output_dir="리사이즈이미지",
    max_width=800
)
```

**🎯 활용 시나리오**:
- 웹사이트용 이미지 최적화
- 썸네일 자동 생성
- 이미지 형식 일괄 변환

**💡 확장 아이디어**:
- 워터마크 자동 추가
- 이미지 품질 압축
- EXIF 데이터 제거 (개인정보 보호)

---

## 8. 재무 데이터 분석 및 리포트

**📝 설명**: 재무 데이터를 분석하고 주요 지표를 계산합니다.

**🔧 필요한 라이브러리**:
```bash
pip install pandas numpy openpyxl
```

**💻 전체 코드**:
```python
import pandas as pd
import numpy as np

# 📌 실습용 샘플 재무 데이터 생성
np.random.seed(42)
dates = pd.date_range(start='2024-01-01', end='2024-12-31', freq='D')
products = ['노트북', '마우스', '키보드', '모니터', '헤드셋']

df = pd.DataFrame({
    '날짜': np.random.choice(dates, 1000),
    '제품': np.random.choice(products, 1000),
    '매출': np.random.randint(50000, 2000000, 1000)
})

df = df.sort_values('날짜')
df.to_excel("financial_data.xlsx", index=False, engine='openpyxl')
print("✅ 샘플 재무 데이터 생성 완료!")

# 날짜 컬럼을 datetime으로 변환
df['날짜'] = pd.to_datetime(df['날짜'])
df = df.sort_values('날짜')

# 1. 월별 매출 및 성장률
monthly_sales = df.groupby(df['날짜'].dt.to_period('M'))['매출'].sum()
monthly_growth = monthly_sales.pct_change() * 100

# 2. 이동 평균 (3개월)
moving_avg = monthly_sales.rolling(window=3).mean()

# 3. 누적 매출
cumulative_sales = monthly_sales.cumsum()

# 4. 주요 통계
report = {
    "총 매출": f"{monthly_sales.sum():,.0f}원",
    "평균 월 매출": f"{monthly_sales.mean():,.0f}원",
    "최고 월 매출": f"{monthly_sales.max():,.0f}원",
    "최저 월 매출": f"{monthly_sales.min():,.0f}원",
    "평균 성장률": f"{monthly_growth.mean():.2f}%",
}

# 5. 상위/하위 제품
top_products = df.groupby('제품')['매출'].sum().sort_values(ascending=False).head(5)
bottom_products = df.groupby('제품')['매출'].sum().sort_values().head(5)

# 리포트 출력
print("=" * 50)
print("재무 분석 리포트")
print("=" * 50)

for key, value in report.items():
    print(f"{key}: {value}")

print("\n📈 Top 5 제품:")
for product, sales in top_products.items():
    print(f"  {product}: {sales:,.0f}원")

print("\n📉 Bottom 5 제품:")
for product, sales in bottom_products.items():
    print(f"  {product}: {sales:,.0f}원")

# 엑셀로 저장
with pd.ExcelWriter('financial_report.xlsx', engine='openpyxl') as writer:
    monthly_sales.to_frame('월별매출').to_excel(writer, sheet_name='월별통계')
    top_products.to_frame('매출').to_excel(writer, sheet_name='상위제품')
    bottom_products.to_frame('매출').to_excel(writer, sheet_name='하위제품')

print("\n✅ 리포트 저장 완료: financial_report.xlsx")
```

**🎯 활용 시나리오**:
- 월간/분기별 재무 보고서
- 제품 성과 분석
- 매출 예측

**💡 확장 아이디어**:
- 시계열 예측 (Prophet, ARIMA)
- 인터랙티브 대시보드 (Plotly Dash)
- 자동 이상치 탐지

---

# 🌐 웹 & API

## 9. 웹 스크래핑 (뉴스, 날씨)

**📝 설명**: 웹사이트에서 실시간 정보를 수집합니다.

**🔧 필요한 라이브러리**:
```bash
pip install requests beautifulsoup4 pandas
```

**💻 전체 코드**:
```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime

def scrape_news(url, max_articles=10):
    """뉴스 스크래핑"""

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, 'html.parser')

    articles = []

    # 뉴스 항목 찾기 (사이트마다 다름 - 예시)
    news_items = soup.find_all('div', class_='news-item', limit=max_articles)

    for item in news_items:
        title = item.find('h2', class_='title').text.strip()
        link = item.find('a')['href']
        date = item.find('span', class_='date').text.strip()

        articles.append({
            '제목': title,
            '링크': link,
            '날짜': date,
            '수집시간': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })

    return articles

# 날씨 정보 가져오기 (OpenWeatherMap API)
def get_weather(city, api_key):
    """날씨 정보 조회"""

    url = f"http://api.openweathermap.org/data/2.5/weather"
    params = {
        'q': city,
        'appid': api_key,
        'units': 'metric',  # 섭씨 온도
        'lang': 'kr'  # 한국어
    }

    response = requests.get(url, params=params)
    data = response.json()

    if response.status_code == 200:
        weather_info = {
            '도시': data['name'],
            '온도': f"{data['main']['temp']}°C",
            '체감온도': f"{data['main']['feels_like']}°C",
            '날씨': data['weather'][0]['description'],
            '습도': f"{data['main']['humidity']}%",
            '풍속': f"{data['wind']['speed']} m/s"
        }
        return weather_info
    else:
        return None

# 실행
news_url = "https://news.example.com"
articles = scrape_news(news_url, max_articles=5)

# 데이터프레임으로 변환
df = pd.DataFrame(articles)
print(df)

# 엑셀로 저장
df.to_excel(f"news_{datetime.now().strftime('%Y%m%d')}.xlsx", index=False)

# 날씨 정보
api_key = "your_openweathermap_api_key"
weather = get_weather("Seoul", api_key)
if weather:
    print("\n[서울 날씨]")
    for key, value in weather.items():
        print(f"{key}: {value}")
```

**🎯 활용 시나리오**:
- 뉴스 모니터링 자동화
- 경쟁사 정보 수집
- 날씨 정보 기반 업무 계획

**💡 확장 아이디어**:
- 키워드 기반 필터링
- 텔레그램으로 알림 전송
- 매 시간마다 자동 실행 (schedule)

---

## 10. 실시간 주식 가격 수집

**📝 설명**: 주식 가격을 실시간으로 수집하고 저장합니다.

**🔧 필요한 라이브러리**:
```bash
pip install yfinance pandas matplotlib
```

### 예시 1: 여러 주식 정보 수집

**💻 코드**:
```python
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta

def get_stock_data(ticker, period='1mo'):
    """주식 데이터 가져오기"""

    stock = yf.Ticker(ticker)

    # 기본 정보
    info = stock.info

    # 가격 데이터
    hist = stock.history(period=period)

    return {
        'info': info,
        'history': hist
    }

# 여러 주식 모니터링
tickers = ['AAPL', 'GOOGL', 'MSFT', '005930.KS']  # 삼성전자
results = []

print("주식 정보 수집 중...")
for ticker in tickers:
    print(f"  {ticker}...", end=' ')

    data = get_stock_data(ticker, period='5d')
    info = data['info']
    hist = data['history']

    if not hist.empty:
        latest = hist.iloc[-1]

        results.append({
            '종목코드': ticker,
            '종목명': info.get('longName', 'N/A'),
            '현재가': f"${latest['Close']:.2f}",
            '전일대비': f"{((latest['Close'] - latest['Open']) / latest['Open'] * 100):.2f}%",
            '거래량': f"{latest['Volume']:,}",
            '최고가(5일)': f"${hist['High'].max():.2f}",
            '최저가(5일)': f"${hist['Low'].min():.2f}",
            '수집시간': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        print("✓")
    else:
        print("✗")

# 데이터프레임으로 출력
df = pd.DataFrame(results)
print("\n" + "="*80)
print(df.to_string(index=False))
print("="*80)

# CSV로 저장
filename = f"stock_prices_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
df.to_csv(filename, index=False, encoding='utf-8-sig')
print(f"\n✅ 저장 완료: {filename}")
```

---

### 예시 2: 주가 차트 시각화

**📝 설명**: 특정 종목의 주가 데이터를 다운로드하고 차트로 시각화합니다.

**💻 코드**:
```python
import yfinance as yf
import matplotlib.pyplot as plt
import pandas as pd

# 한글 폰트 설정
plt.rcParams['font.family'] = 'AppleGothic'  # Mac
# plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows
plt.rcParams['axes.unicode_minus'] = False

# 삼성전자 1년치 데이터 다운로드
ticker = "005930.KS"
stock = yf.Ticker(ticker)
df = stock.history(period="1y")

print(f"데이터 기간: {df.index[0].date()} ~ {df.index[-1].date()}")
print(f"데이터 개수: {len(df)}일")

# 차트 생성
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), gridspec_kw={'height_ratios': [3, 1]})
fig.suptitle(f'{stock.info.get("longName", ticker)} 주가 차트 (최근 1년)', fontsize=16, fontweight='bold')

# 주가 차트 (종가)
ax1.plot(df.index, df['Close'], label='종가', linewidth=2, color='')
ax1.fill_between(df.index, df['Low'], df['High'], alpha=0.2, color='', label='고가-저가 범위')
ax1.set_ylabel('가격 (원)', fontsize=12)
ax1.legend(loc='best')
ax1.grid(True, alpha=0.3)

# 통계 정보 표시
current_price = df['Close'].iloc[-1]
max_price = df['High'].max()
min_price = df['Low'].min()
ax1.axhline(y=current_price, color='red', linestyle='--', alpha=0.5, label=f'현재가: {current_price:,.0f}원')
ax1.text(df.index[-1], current_price, f' {current_price:,.0f}원', verticalalignment='center')

# 거래량 차트
colors = ['red' if df['Close'].iloc[i] >= df['Open'].iloc[i] else 'blue' for i in range(len(df))]
ax2.bar(df.index, df['Volume'], color=colors, alpha=0.5, width=0.8)
ax2.set_ylabel('거래량', fontsize=12)
ax2.set_xlabel('날짜', fontsize=12)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('samsung_stock_chart.png', dpi=300, bbox_inches='tight')
print("\n✅ 차트 저장 완료: samsung_stock_chart.png")
plt.show()

# 통계 요약
print(f"\n📊 주가 통계 (최근 1년)")
print(f"현재가: {current_price:,.0f}원")
print(f"최고가: {max_price:,.0f}원 ({df['High'].idxmax().date()})")
print(f"최저가: {min_price:,.0f}원 ({df['Low'].idxmin().date()})")
print(f"변동폭: {((current_price - df['Close'].iloc[0]) / df['Close'].iloc[0] * 100):.2f}%")
print(f"평균 거래량: {df['Volume'].mean():,.0f}주")
```

---

### 예시 3: 이동평균선과 매매 신호 탐지

**📝 설명**: 5일/20일 이동평균선을 계산하고 골든크로스/데드크로스를 탐지합니다.

**💻 코드**:
```python
import yfinance as yf
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# 한글 폰트 설정
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# 데이터 다운로드
ticker = "005930.KS"
stock = yf.Ticker(ticker)
df = stock.history(period="6mo")

# 이동평균선 계산
df['MA5'] = df['Close'].rolling(window=5).mean()
df['MA20'] = df['Close'].rolling(window=20).mean()

# 골든크로스/데드크로스 탐지
df['Signal'] = 0
df.loc[df['MA5'] > df['MA20'], 'Signal'] = 1  # 골든크로스
df.loc[df['MA5'] < df['MA20'], 'Signal'] = -1  # 데드크로스

# 신호 변화 지점 찾기 (크로스 발생 시점)
df['Signal_Change'] = df['Signal'].diff()
golden_cross = df[df['Signal_Change'] == 2]  # -1에서 1로
dead_cross = df[df['Signal_Change'] == -2]  # 1에서 -1로

# 차트 그리기
plt.figure(figsize=(14, 8))
plt.plot(df.index, df['Close'], label='종가', linewidth=2, color='black', alpha=0.7)
plt.plot(df.index, df['MA5'], label='5일 이동평균', linewidth=1.5, color='blue')
plt.plot(df.index, df['MA20'], label='20일 이동평균', linewidth=1.5, color='red')

# 골든크로스 표시 (매수 신호)
if not golden_cross.empty:
    plt.scatter(golden_cross.index, golden_cross['Close'],
                color='green', marker='^', s=200, label='골든크로스 (매수)', zorder=5)

# 데드크로스 표시 (매도 신호)
if not dead_cross.empty:
    plt.scatter(dead_cross.index, dead_cross['Close'],
                color='red', marker='v', s=200, label='데드크로스 (매도)', zorder=5)

plt.title(f'{stock.info.get("longName", ticker)} - 이동평균선 & 매매 신호', fontsize=16, fontweight='bold')
plt.xlabel('날짜', fontsize=12)
plt.ylabel('가격 (원)', fontsize=12)
plt.legend(loc='best', fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('moving_average_signals.png', dpi=300, bbox_inches='tight')
print("✅ 차트 저장 완료: moving_average_signals.png")
plt.show()

# 신호 요약
print(f"\n📊 매매 신호 요약 (최근 6개월)")
print(f"\n🟢 골든크로스 (매수 신호): {len(golden_cross)}회")
if not golden_cross.empty:
    for date, row in golden_cross.iterrows():
        print(f"  - {date.date()}: {row['Close']:,.0f}원")

print(f"\n🔴 데드크로스 (매도 신호): {len(dead_cross)}회")
if not dead_cross.empty:
    for date, row in dead_cross.iterrows():
        print(f"  - {date.date()}: {row['Close']:,.0f}원")

# 현재 상태
current_signal = "골든크로스 (상승 추세)" if df['Signal'].iloc[-1] == 1 else "데드크로스 (하락 추세)"
print(f"\n💡 현재 상태: {current_signal}")
print(f"   MA5: {df['MA5'].iloc[-1]:,.0f}원")
print(f"   MA20: {df['MA20'].iloc[-1]:,.0f}원")
```

---

### 예시 4: 여러 종목 수익률 비교

**📝 설명**: 여러 종목의 수익률을 비교하여 투자 성과를 분석합니다.

**💻 코드**:
```python
import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 한글 폰트 설정
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# 비교할 종목 리스트
tickers = {
    '005930.KS': '삼성전자',
    '000660.KS': 'SK하이닉스',
    '035420.KS': 'NAVER',
    '035720.KS': '카카오',
    '051910.KS': 'LG화학'
}

# 1년치 데이터 다운로드
period = "1y"
data = {}

print("📥 데이터 다운로드 중...\n")
for ticker, name in tickers.items():
    print(f"  {name} ({ticker})...", end=' ')
    stock = yf.Ticker(ticker)
    hist = stock.history(period=period)

    if not hist.empty:
        # 수익률 계산 (첫날 대비 퍼센트)
        start_price = hist['Close'].iloc[0]
        hist['Return'] = ((hist['Close'] - start_price) / start_price) * 100
        data[name] = hist['Return']
        print("✓")
    else:
        print("✗")

# 데이터프레임 생성
df_returns = pd.DataFrame(data)

# 수익률 차트
plt.figure(figsize=(14, 8))
for column in df_returns.columns:
    plt.plot(df_returns.index, df_returns[column], label=column, linewidth=2)

plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)
plt.title('주요 종목 수익률 비교 (최근 1년)', fontsize=16, fontweight='bold')
plt.xlabel('날짜', fontsize=12)
plt.ylabel('수익률 (%)', fontsize=12)
plt.legend(loc='best', fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('stock_returns_comparison.png', dpi=300, bbox_inches='tight')
print("\n✅ 차트 저장 완료: stock_returns_comparison.png")
plt.show()

# 수익률 통계
print("\n📊 수익률 통계 (최근 1년)\n")
print("="*70)
print(f"{'종목':<15} {'현재 수익률':<12} {'최고 수익률':<12} {'최저 수익률':<12} {'변동성':<10}")
print("="*70)

for name in df_returns.columns:
    current_return = df_returns[name].iloc[-1]
    max_return = df_returns[name].max()
    min_return = df_returns[name].min()
    volatility = df_returns[name].std()

    print(f"{name:<15} {current_return:>10.2f}% {max_return:>10.2f}% {min_return:>10.2f}% {volatility:>8.2f}%")

print("="*70)

# 최고/최저 수익률 종목
best_stock = df_returns.iloc[-1].idxmax()
worst_stock = df_returns.iloc[-1].idxmin()
print(f"\n🏆 최고 수익률: {best_stock} ({df_returns[best_stock].iloc[-1]:.2f}%)")
print(f"📉 최저 수익률: {worst_stock} ({df_returns[worst_stock].iloc[-1]:.2f}%)")

# 평균 수익률
avg_return = df_returns.iloc[-1].mean()
print(f"\n📊 평균 수익률: {avg_return:.2f}%")
```

---

### 예시 5: 배당금 정보 및 배당 수익률

**📝 설명**: 종목의 배당금 이력과 배당 수익률을 조회합니다.

**💻 코드**:
```python
import yfinance as yf
import pandas as pd
from datetime import datetime

# 배당주 종목 리스트
dividend_stocks = {
    '005930.KS': '삼성전자',
    '000660.KS': 'SK하이닉스',
    '015760.KS': '한국전력',
    '033780.KS': 'KT&G',
    '105560.KS': 'KB금융'
}

print("📊 배당금 정보 조회\n")
print("="*90)

results = []

for ticker, name in dividend_stocks.items():
    print(f"\n🔍 {name} ({ticker})")
    print("-"*90)

    stock = yf.Ticker(ticker)
    info = stock.info

    # 배당 정보
    dividend_yield = info.get('dividendYield', 0)
    dividend_rate = info.get('dividendRate', 0)
    current_price = info.get('currentPrice', info.get('regularMarketPrice', 0))

    # 배당 이력
    dividends = stock.dividends

    if not dividends.empty:
        # 최근 1년 배당금
        recent_dividends = dividends[dividends.index > pd.Timestamp.now() - pd.DateOffset(years=1)]
        total_dividend_1y = recent_dividends.sum()

        # 배당 수익률 계산
        if current_price > 0:
            calculated_yield = (total_dividend_1y / current_price) * 100
        else:
            calculated_yield = 0

        print(f"현재가: {current_price:,.0f}원")
        print(f"최근 1년 배당금 합계: {total_dividend_1y:,.0f}원")
        print(f"배당 수익률: {calculated_yield:.2f}%")

        # 최근 배당 이력 (최근 5회)
        print(f"\n최근 배당 이력:")
        for date, amount in recent_dividends.tail().items():
            print(f"  {date.date()}: {amount:,.0f}원")

        results.append({
            '종목': name,
            '티커': ticker,
            '현재가': f"{current_price:,.0f}원",
            '연간 배당금': f"{total_dividend_1y:,.0f}원",
            '배당 수익률': f"{calculated_yield:.2f}%",
            '배당 횟수': len(recent_dividends)
        })
    else:
        print("배당 정보 없음")
        results.append({
            '종목': name,
            '티커': ticker,
            '현재가': f"{current_price:,.0f}원",
            '연간 배당금': '-',
            '배당 수익률': '-',
            '배당 횟수': 0
        })

# 결과 요약
print("\n" + "="*90)
print("\n📋 배당 수익률 종합 비교\n")

df_results = pd.DataFrame(results)
print(df_results.to_string(index=False))

# 배당 수익률 기준 정렬 (문자열 처리)
df_sorted = df_results.copy()
df_sorted['배당_수익률_숫자'] = df_sorted['배당 수익률'].str.replace('%', '').str.replace('-', '0').astype(float)
df_sorted = df_sorted.sort_values('배당_수익률_숫자', ascending=False)

print(f"\n🏆 배당 수익률 Top 3:")
for idx, row in df_sorted.head(3).iterrows():
    if row['배당 수익률'] != '-':
        print(f"  {idx+1}. {row['종목']}: {row['배당 수익률']}")

# CSV 저장
df_results.to_csv(f"dividend_info_{datetime.now().strftime('%Y%m%d')}.csv",
                   index=False, encoding='utf-8-sig')
print(f"\n✅ 배당 정보 저장 완료: dividend_info_{datetime.now().strftime('%Y%m%d')}.csv")
```

---

**🎯 활용 시나리오**:
- 포트폴리오 모니터링
- 가격 알림 시스템
- 투자 분석 자동화

**💡 확장 아이디어**:
- **예시 1**: 가격 변동 시 알림 전송
- **예시 2**: 캔들스틱 차트 추가, 볼린저 밴드 표시
- **예시 3**: RSI, MACD 등 추가 기술적 지표 계산
- **예시 4**: 샤프 비율, 최대 낙폭(MDD) 계산
- **예시 5**: 배당 재투자 수익률 시뮬레이션
- 실시간 데이터 스트리밍 (WebSocket 활용)
- 자동 매매 시스템 (신중! 법적 검토 필요)

---

## 11. API 서버 만들기 (Flask)

**📝 설명**: 간단한 REST API 서버를 만듭니다.

**🔧 필요한 라이브러리**:
```bash
pip install flask pandas
```

**💻 전체 코드**:
```python
from flask import Flask, jsonify, request
import pandas as pd
from datetime import datetime

app = Flask(__name__)

# 메모리 데이터베이스 (실제로는 DB 사용)
tasks = []
task_id_counter = 1

@app.route('/')
def home():
    """홈 페이지"""
    return jsonify({
        "message": "할일 관리 API",
        "endpoints": {
            "GET /tasks": "모든 할일 조회",
            "POST /tasks": "할일 추가",
            "PUT /tasks/<id>": "할일 수정",
            "DELETE /tasks/<id>": "할일 삭제"
        }
    })

@app.route('/tasks', methods=['GET'])
def get_tasks():
    """모든 할일 조회"""
    return jsonify(tasks)

@app.route('/tasks', methods=['POST'])
def create_task():
    """할일 추가"""
    global task_id_counter

    data = request.get_json()

    new_task = {
        'id': task_id_counter,
        'title': data['title'],
        'completed': False,
        'created_at': datetime.now().isoformat()
    }

    tasks.append(new_task)
    task_id_counter += 1

    return jsonify(new_task), 201

@app.route('/tasks/<int:task_id>', methods=['PUT'])
def update_task(task_id):
    """할일 수정"""
    data = request.get_json()

    for task in tasks:
        if task['id'] == task_id:
            task['title'] = data.get('title', task['title'])
            task['completed'] = data.get('completed', task['completed'])
            task['updated_at'] = datetime.now().isoformat()
            return jsonify(task)

    return jsonify({'error': 'Task not found'}), 404

@app.route('/tasks/<int:task_id>', methods=['DELETE'])
def delete_task(task_id):
    """할일 삭제"""
    global tasks

    tasks = [t for t in tasks if t['id'] != task_id]
    return jsonify({'message': 'Task deleted'})

if __name__ == '__main__':
    print("🚀 서버 시작: http://localhost:5000")
    app.run(debug=True, port=5000)
```

**🎯 활용 시나리오**:
- 내부 팀용 API 개발
- 마이크로서비스 구축
- 모바일 앱 백엔드

**💡 확장 아이디어**:
- 데이터베이스 연동 (SQLite, PostgreSQL)
- 인증/인가 추가 (JWT)
- 배포 (Heroku, AWS)

---

## 12. 웹사이트 자동 로그인

**📝 설명**: Selenium을 사용하여 웹사이트에 자동 로그인합니다.

**🔧 필요한 라이브러리**:
```bash
pip install selenium
# Chrome 드라이버도 별도로 설치 필요: https://chromedriver.chromium.org/
```

**💻 전체 코드**:
```python
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
import time

def auto_login(url, username, password):
    """자동 로그인"""

    # Chrome 드라이버 설정
    options = webdriver.ChromeOptions()
    # options.add_argument('--headless')  # 백그라운드 실행
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    driver = webdriver.Chrome(options=options)

    try:
        # 웹사이트 열기
        print(f"🌐 {url} 접속 중...")
        driver.get(url)

        # 페이지 로드 대기
        wait = WebDriverWait(driver, 10)

        # 로그인 폼 찾기 (ID로)
        username_field = wait.until(
            EC.presence_of_element_located((By.ID, "username"))
        )
        password_field = driver.find_element(By.ID, "password")
        login_button = driver.find_element(By.ID, "login-button")

        # 정보 입력
        print("📝 로그인 정보 입력 중...")
        username_field.send_keys(username)
        time.sleep(0.5)
        password_field.send_keys(password)
        time.sleep(0.5)

        # 로그인 버튼 클릭
        print("🔐 로그인 시도...")
        login_button.click()

        # 로그인 성공 확인 (URL 변경 또는 특정 요소 대기)
        wait.until(
            EC.url_contains("dashboard")  # 로그인 후 이동하는 페이지
        )

        print("✅ 로그인 성공!")

        # 여기서 필요한 작업 수행
        # 예: 데이터 수집, 파일 다운로드 등

        time.sleep(2)

    except Exception as e:
        print(f"❌ 에러 발생: {e}")

    finally:
        # 브라우저 종료
        driver.quit()
        print("🔚 브라우저 종료")

# 실행
auto_login(
    url="https://example.com/login",
    username="your_username",
    password="your_password"
)
```

**🎯 활용 시나리오**:
- 출퇴근 체크 자동화
- 정기 보고서 다운로드
- 웹사이트 모니터링

**💡 확장 아이디어**:
- 2단계 인증 처리
- 스크린샷 자동 저장
- 에러 발생 시 알림

---

## 13. 파일 다운로드 자동화

**📝 설명**: 웹사이트에서 파일을 자동으로 다운로드합니다.

**🔧 필요한 라이브러리**:
```bash
pip install requests tqdm
```

**💻 전체 코드**:
```python
import requests
from pathlib import Path
from tqdm import tqdm
import os

def download_file(url, save_path, chunk_size=8192):
    """파일 다운로드 (진행률 표시)"""

    # 저장 디렉토리 생성
    Path(save_path).parent.mkdir(parents=True, exist_ok=True)

    # 파일 크기 가져오기
    response = requests.head(url)
    total_size = int(response.headers.get('content-length', 0))

    # 다운로드
    print(f"📥 다운로드 시작: {url}")
    print(f"   저장 위치: {save_path}")
    print(f"   파일 크기: {total_size / (1024*1024):.2f} MB")

    response = requests.get(url, stream=True)
    response.raise_for_status()

    # 진행률 표시바
    with open(save_path, 'wb') as file:
        with tqdm(total=total_size, unit='B', unit_scale=True, desc="진행") as pbar:
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    file.write(chunk)
                    pbar.update(len(chunk))

    print("✅ 다운로드 완료!")
    return save_path

def batch_download(url_list, save_dir):
    """여러 파일 일괄 다운로드"""

    Path(save_dir).mkdir(parents=True, exist_ok=True)

    results = []

    for idx, url in enumerate(url_list, 1):
        print(f"\n[{idx}/{len(url_list)}]")

        # 파일명 추출
        filename = url.split('/')[-1]
        save_path = os.path.join(save_dir, filename)

        try:
            download_file(url, save_path)
            results.append({'url': url, 'status': 'success', 'path': save_path})
        except Exception as e:
            print(f"❌ 다운로드 실패: {e}")
            results.append({'url': url, 'status': 'failed', 'error': str(e)})

    return results

# 실행 예시
urls = [
    "https://example.com/file1.pdf",
    "https://example.com/file2.xlsx",
    "https://example.com/file3.zip",
]

results = batch_download(urls, save_dir="downloads")

# 결과 요약
print("\n" + "="*60)
print("다운로드 결과 요약")
print("="*60)
success = len([r for r in results if r['status'] == 'success'])
failed = len([r for r in results if r['status'] == 'failed'])
print(f"성공: {success}개")
print(f"실패: {failed}개")
```

**🎯 활용 시나리오**:
- 정기 보고서 자동 다운로드
- 데이터셋 일괄 수집
- 백업 파일 다운로드

**💡 확장 아이디어**:
- 다운로드 재시도 로직
- 파일 무결성 검증 (해시 체크)
- 병렬 다운로드로 속도 향상

---

## 14. REST API 호출 및 데이터 저장

**📝 설명**: 외부 API를 호출하고 데이터를 가공하여 저장합니다.

**🔧 필요한 라이브러리**:
```bash
pip install requests pandas
```

**💻 전체 코드**:
```python
import requests
import pandas as pd
from datetime import datetime
import json

class APIClient:
    """API 클라이언트 클래스"""

    def __init__(self, base_url, api_key=None):
        self.base_url = base_url
        self.api_key = api_key
        self.headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {api_key}' if api_key else None
        }

    def get(self, endpoint, params=None):
        """GET 요청"""
        url = f"{self.base_url}/{endpoint}"
        response = requests.get(url, headers=self.headers, params=params)
        response.raise_for_status()
        return response.json()

    def post(self, endpoint, data):
        """POST 요청"""
        url = f"{self.base_url}/{endpoint}"
        response = requests.post(url, headers=self.headers, json=data)
        response.raise_for_status()
        return response.json()

# 사용 예시: GitHub API
def get_github_repos(username):
    """GitHub 사용자의 레포지토리 정보 가져오기"""

    client = APIClient("https://api.github.com")

    # 레포지토리 목록 가져오기
    repos = client.get(f"users/{username}/repos")

    # 데이터 가공
    repo_data = []
    for repo in repos:
        repo_data.append({
            '이름': repo['name'],
            '설명': repo['description'],
            '언어': repo['language'],
            '⭐Stars': repo['stargazers_count'],
            '🍴Forks': repo['forks_count'],
            '생성일': repo['created_at'][:10],
            'URL': repo['html_url']
        })

    return repo_data

# 실행
username = "torvalds"  # Linux 창시자
print(f"📊 {username}의 레포지토리 정보 수집 중...")

repos = get_github_repos(username)

# 데이터프레임으로 변환
df = pd.DataFrame(repos)

# 별(stars) 순으로 정렬
df = df.sort_values('⭐Stars', ascending=False)

print(f"\n총 {len(df)}개 레포지토리")
print("\nTop 5 레포지토리:")
print(df.head().to_string(index=False))

# 저장
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
excel_file = f"github_{username}_{timestamp}.xlsx"
json_file = f"github_{username}_{timestamp}.json"

df.to_excel(excel_file, index=False)
df.to_json(json_file, orient='records', indent=2, force_ascii=False)

print(f"\n✅ 저장 완료:")
print(f"  - {excel_file}")
print(f"  - {json_file}")
```

**🎯 활용 시나리오**:
- 오픈소스 프로젝트 모니터링
- SNS 데이터 수집 및 분석
- API 기반 서비스 통합

**💡 확장 아이디어**:
- API 속도 제한 처리 (rate limiting)
- 페이지네이션 자동 처리
- 실시간 데이터 모니터링

---

# 🤖 AI & 챗봇

## 15. AI 챗봇 만들기

**📝 설명**: Claude API를 사용하여 대화형 챗봇을 만듭니다.

**🔧 필요한 라이브러리**:
```bash
pip install anthropic
```

**💻 전체 코드**:
```python
import anthropic
from datetime import datetime

class SimpleChatbot:
    """간단한 AI 챗봇"""

    def __init__(self, api_key):
        self.client = anthropic.Anthropic(api_key=api_key)
        self.conversation_history = []
        self.model = "claude-3-5-sonnet-20241022"

    def chat(self, user_message):
        """사용자 메시지에 응답"""

        # 대화 이력에 추가
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # API 호출
        response = self.client.messages.create(
            model=self.model,
            max_tokens=1024,
            messages=self.conversation_history
        )

        # 응답 추출
        assistant_message = response.content[0].text

        # 대화 이력에 추가
        self.conversation_history.append({
            "role": "assistant",
            "content": assistant_message
        })

        return assistant_message

    def save_conversation(self, filename=None):
        """대화 이력 저장"""
        if filename is None:
            filename = f"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        with open(filename, 'w', encoding='utf-8') as f:
            for msg in self.conversation_history:
                role = "사용자" if msg["role"] == "user" else "AI"
                f.write(f"[{role}]\n{msg['content']}\n\n")

        print(f"✅ 대화 저장 완료: {filename}")

# 사용 예시
def main():
    # 챗봇 초기화
    api_key = "your-api-key"
    chatbot = SimpleChatbot(api_key)

    print("="*60)
    print("AI 챗봇 (종료: 'quit' 또는 'exit')")
    print("="*60)

    while True:
        # 사용자 입력
        user_input = input("\n사용자: ").strip()

        # 종료 명령
        if user_input.lower() in ['quit', 'exit', '종료']:
            print("\n챗봇을 종료합니다.")

            # 대화 저장
            save = input("대화 내용을 저장하시겠습니까? (y/n): ")
            if save.lower() == 'y':
                chatbot.save_conversation()

            break

        # 빈 입력 무시
        if not user_input:
            continue

        # AI 응답
        try:
            response = chatbot.chat(user_input)
            print(f"\nAI: {response}")
        except Exception as e:
            print(f"\n오류 발생: {e}")

if __name__ == "__main__":
    main()
```

**🎯 활용 시나리오**:
- 고객 서비스 챗봇
- 개인 비서 AI
- 교육용 튜터 봇

**💡 확장 아이디어**:
- 웹 인터페이스 추가 (Streamlit)
- 음성 입출력 (TTS, STT)
- 특정 도메인 전문화 (프롬프트 엔지니어링)

---

## 16. 이미지 분석 자동화

**📝 설명**: AI를 사용하여 이미지를 분석하고 설명을 생성합니다.

**🔧 필요한 라이브러리**:
```bash
pip install anthropic Pillow
```

**💻 전체 코드**:
```python
import anthropic
import base64
from pathlib import Path
import os

def encode_image(image_path):
    """이미지를 base64로 인코딩"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def analyze_image(image_path, api_key, prompt="이 이미지에 대해 상세히 설명해주세요."):
    """이미지 분석"""

    # 이미지 타입 판별
    ext = Path(image_path).suffix.lower()
    media_types = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp'
    }
    media_type = media_types.get(ext, 'image/jpeg')

    # 이미지 인코딩
    image_data = encode_image(image_path)

    # Claude API 호출
    client = anthropic.Anthropic(api_key=api_key)

    message = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": media_type,
                            "data": image_data,
                        },
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ],
            }
        ],
    )

    return message.content[0].text

def batch_analyze_images(image_folder, api_key):
    """폴더 내 모든 이미지 분석"""

    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']

    # 이미지 파일 찾기
    image_files = [
        f for f in os.listdir(image_folder)
        if Path(f).suffix.lower() in image_extensions
    ]

    print(f"📸 분석할 이미지: {len(image_files)}개\n")

    results = []

    for idx, filename in enumerate(image_files, 1):
        image_path = os.path.join(image_folder, filename)

        print(f"[{idx}/{len(image_files)}] {filename} 분석 중...")

        try:
            description = analyze_image(
                image_path,
                api_key,
                prompt="이 이미지를 한국어로 상세히 설명해주세요. 주요 객체, 색상, 분위기 등을 포함하여 설명해주세요."
            )

            results.append({
                '파일명': filename,
                '설명': description,
                '경로': image_path
            })

            print(f"✅ 완료\n")

        except Exception as e:
            print(f"❌ 에러: {e}\n")
            results.append({
                '파일명': filename,
                '설명': f"분석 실패: {e}",
                '경로': image_path
            })

    return results

# 실행
api_key = "your-api-key"
image_folder = "images"

results = batch_analyze_images(image_folder, api_key)

# 결과 출력
print("="*80)
print("분석 결과")
print("="*80)

for result in results:
    print(f"\n📷 {result['파일명']}")
    print(f"   {result['설명'][:200]}...")

# 텍스트 파일로 저장
with open("image_analysis_results.txt", 'w', encoding='utf-8') as f:
    for result in results:
        f.write(f"파일명: {result['파일명']}\n")
        f.write(f"경로: {result['경로']}\n")
        f.write(f"설명: {result['설명']}\n")
        f.write("\n" + "="*80 + "\n\n")

print("\n✅ 결과 저장 완료: image_analysis_results.txt")
```

**🎯 활용 시나리오**:
- 제품 이미지 자동 태깅
- 사진 라이브러리 정리
- 접근성 개선 (alt text 생성)

**💡 확장 아이디어**:
- 이미지 분류 및 폴더 자동 정리
- 이미지 품질 평가
- 부적절한 콘텐츠 필터링

---

## 17. 문서 요약 자동화

**📝 설명**: 긴 문서를 AI로 자동 요약합니다.

**🔧 필요한 라이브러리**:
```bash
pip install anthropic PyPDF2
```

**💻 전체 코드**:
```python
import anthropic
import PyPDF2
from pathlib import Path

def read_pdf(pdf_path):
    """PDF 파일 읽기"""
    text = ""
    with open(pdf_path, 'rb') as file:
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

def read_text_file(file_path):
    """텍스트 파일 읽기"""
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

def summarize_document(text, api_key, summary_type="간단"):
    """문서 요약"""

    client = anthropic.Anthropic(api_key=api_key)

    # 요약 스타일에 따른 프롬프트
    prompts = {
        "간단": "다음 문서를 3-5문장으로 간단히 요약해주세요.",
        "상세": "다음 문서의 주요 내용을 단락별로 상세히 요약해주세요.",
        "핵심": "다음 문서의 핵심 포인트를 bullet points로 정리해주세요."
    }

    prompt = prompts.get(summary_type, prompts["간단"])

    message = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=2048,
        messages=[
            {
                "role": "user",
                "content": f"{prompt}\n\n문서 내용:\n{text[:100000]}"  # 최대 100K 문자
            }
        ]
    )

    return message.content[0].text

def batch_summarize(file_paths, api_key, summary_type="간단"):
    """여러 문서 일괄 요약"""

    results = []

    for idx, file_path in enumerate(file_paths, 1):
        print(f"[{idx}/{len(file_paths)}] {Path(file_path).name} 요약 중...")

        try:
            # 파일 타입에 따라 읽기
            ext = Path(file_path).suffix.lower()
            if ext == '.pdf':
                text = read_pdf(file_path)
            else:
                text = read_text_file(file_path)

            # 요약
            summary = summarize_document(text, api_key, summary_type)

            results.append({
                '파일명': Path(file_path).name,
                '원본길이': len(text),
                '요약': summary
            })

            print(f"✅ 완료 (원본: {len(text):,}자 → 요약: {len(summary)}자)\n")

        except Exception as e:
            print(f"❌ 에러: {e}\n")
            results.append({
                '파일명': Path(file_path).name,
                '원본길이': 0,
                '요약': f"요약 실패: {e}"
            })

    return results

# 실행
api_key = "your-api-key"

files = [
    "report1.pdf",
    "report2.txt",
    "article.txt"
]

results = batch_summarize(files, api_key, summary_type="핵심")

# 결과 저장
with open("summaries.txt", 'w', encoding='utf-8') as f:
    f.write("문서 요약 결과\n")
    f.write("="*80 + "\n\n")

    for result in results:
        f.write(f"📄 {result['파일명']}\n")
        f.write(f"원본 길이: {result['원본길이']:,}자\n\n")
        f.write(f"요약:\n{result['요약']}\n")
        f.write("\n" + "="*80 + "\n\n")

print("✅ 요약 저장 완료: summaries.txt")
```

**🎯 활용 시나리오**:
- 뉴스 기사 요약
- 연구 논문 요약
- 회의록 요약

**💡 확장 아이디어**:
- 다국어 번역 + 요약
- 키워드 자동 추출
- 요약의 요약 (계층적 요약)

---

## 18. 음성을 텍스트로 변환

**📝 설명**: 음성 파일을 텍스트로 변환합니다.

**🔧 필요한 라이브러리**:
```bash
pip install SpeechRecognition pydub
# ffmpeg도 별도로 설치 필요 (macOS: brew install ffmpeg)
```

**💻 전체 코드**:
```python
import speech_recognition as sr
from pydub import AudioSegment
from pydub.silence import split_on_silence
import os

def convert_audio_to_wav(audio_path):
    """오디오 파일을 WAV로 변환"""

    audio = AudioSegment.from_file(audio_path)
    wav_path = audio_path.rsplit('.', 1)[0] + '.wav'
    audio.export(wav_path, format='wav')

    return wav_path

def transcribe_audio(audio_path, language='ko-KR'):
    """음성을 텍스트로 변환"""

    recognizer = sr.Recognizer()

    # 오디오 파일 로드
    with sr.AudioFile(audio_path) as source:
        # 노이즈 제거
        recognizer.adjust_for_ambient_noise(source)

        # 오디오 읽기
        audio_data = recognizer.record(source)

        try:
            # Google Speech Recognition 사용
            text = recognizer.recognize_google(audio_data, language=language)
            return text

        except sr.UnknownValueError:
            return "[인식 불가]"
        except sr.RequestError as e:
            return f"[API 에러: {e}]"

def transcribe_long_audio(audio_path, language='ko-KR'):
    """긴 음성 파일을 청크로 나눠서 변환"""

    # 오디오 로드
    sound = AudioSegment.from_file(audio_path)

    # 침묵 기준으로 나누기
    chunks = split_on_silence(
        sound,
        min_silence_len=500,  # 최소 침묵 길이 (ms)
        silence_thresh=sound.dBFS - 14,  # 침묵 기준
        keep_silence=250  # 침묵 부분 유지 (ms)
    )

    print(f"음성을 {len(chunks)}개 청크로 분할했습니다.")

    # 임시 폴더 생성
    temp_folder = "temp_chunks"
    os.makedirs(temp_folder, exist_ok=True)

    # 전체 텍스트
    full_text = []

    # 각 청크 처리
    for idx, chunk in enumerate(chunks):
        # 청크 저장
        chunk_path = os.path.join(temp_folder, f"chunk{idx}.wav")
        chunk.export(chunk_path, format="wav")

        # 텍스트 변환
        print(f"[{idx+1}/{len(chunks)}] 청크 변환 중...", end=' ')
        text = transcribe_audio(chunk_path, language)

        if text != "[인식 불가]":
            full_text.append(text)
            print(f"✓ ({len(text)}자)")
        else:
            print("✗ (인식 실패)")

        # 임시 파일 삭제
        os.remove(chunk_path)

    # 임시 폴더 삭제
    os.rmdir(temp_folder)

    return " ".join(full_text)

# 실행
audio_file = "meeting_recording.mp3"

print(f"🎤 음성 파일 변환 중: {audio_file}\n")

# WAV로 변환
wav_file = convert_audio_to_wav(audio_file)

# 텍스트 변환
text = transcribe_long_audio(wav_file, language='ko-KR')

print("\n" + "="*80)
print("변환 결과")
print("="*80)
print(text)

# 텍스트 파일로 저장
output_file = audio_file.rsplit('.', 1)[0] + '_transcript.txt'
with open(output_file, 'w', encoding='utf-8') as f:
    f.write(text)

print(f"\n✅ 변환 완료: {output_file}")

# WAV 파일 삭제 (원본 유지)
os.remove(wav_file)
```

**🎯 활용 시나리오**:
- 회의록 자동 작성
- 강의 자막 생성
- 인터뷰 전사

**💡 확장 아이디어**:
- 화자 구분 (Speaker diarization)
- 실시간 변환
- 번역 + 변환

---

# ⚡ 자동화 & 생산성

## 19. 작업 스케줄링 (매일 9시 실행)

**📝 설명**: 특정 작업을 정해진 시간에 자동 실행합니다.

**🔧 필요한 라이브러리**:
```bash
pip install schedule
# smtplib는 Python 기본 라이브러리
```

**💻 전체 코드**:
```python
import schedule
import time
from datetime import datetime
import smtplib
from email.mime.text import MIMEText

def daily_report():
    """매일 실행할 작업"""
    print(f"\n[{datetime.now()}] 일일 보고서 생성 중...")

    # 여기서 실제 작업 수행
    # 예: 데이터 수집, 분석, 보고서 생성 등

    report = f"""
    === 일일 보고서 ({datetime.now().strftime('%Y-%m-%d')}) ===

    1. 데이터 수집 완료
    2. 분석 완료
    3. 보고서 생성 완료

    작업 완료 시각: {datetime.now().strftime('%H:%M:%S')}
    """

    print(report)

    # 보고서 저장
    filename = f"daily_report_{datetime.now().strftime('%Y%m%d')}.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"✅ 보고서 저장: {filename}")

    # 이메일 전송 (선택사항)
    # send_email("recipient@example.com", "일일 보고서", report)

def weekly_backup():
    """매주 일요일 실행"""
    print(f"\n[{datetime.now()}] 주간 백업 시작...")
    # 백업 로직
    print("✅ 백업 완료")

def hourly_check():
    """매 시간 실행"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] 시간당 체크 완료")

# 스케줄 등록
schedule.every().day.at("09:00").do(daily_report)  # 매일 오전 9시
schedule.every().day.at("18:00").do(daily_report)  # 매일 오후 6시

schedule.every().sunday.at("02:00").do(weekly_backup)  # 매주 일요일 새벽 2시

schedule.every().hour.do(hourly_check)  # 매시간

# 즉시 실행 옵션
schedule.every().minute.do(hourly_check)  # 매분 (테스트용)

# 스케줄러 실행
print("🚀 스케줄러 시작!")
print("등록된 작업:")
for job in schedule.get_jobs():
    print(f"  - {job}")

try:
    while True:
        schedule.run_pending()
        time.sleep(1)
except KeyboardInterrupt:
    print("\n⏹️  스케줄러 종료")
```

**🎯 활용 시나리오**:
- 매일 아침 보고서 자동 전송
- 정기 백업
- 주기적인 데이터 수집

**💡 확장 아이디어**:
- 실행 결과 로그 저장
- 실패 시 재시도
- 웹 대시보드로 모니터링

---

## 20. 시스템 모니터링 및 알림

**📝 설명**: 시스템 리소스를 모니터링하고 임계값 초과 시 알림을 전송합니다.

**🔧 필요한 라이브러리**:
```bash
pip install psutil
```

**💻 전체 코드**:
```python
import psutil
import time
from datetime import datetime

def get_system_info():
    """시스템 정보 수집"""

    # CPU 사용률
    cpu_percent = psutil.cpu_percent(interval=1)
    cpu_count = psutil.cpu_count()

    # 메모리
    memory = psutil.virtual_memory()
    memory_percent = memory.percent
    memory_used_gb = memory.used / (1024**3)
    memory_total_gb = memory.total / (1024**3)

    # 디스크
    disk = psutil.disk_usage('/')
    disk_percent = disk.percent
    disk_used_gb = disk.used / (1024**3)
    disk_total_gb = disk.total / (1024**3)

    # 네트워크
    net_io = psutil.net_io_counters()
    bytes_sent_mb = net_io.bytes_sent / (1024**2)
    bytes_recv_mb = net_io.bytes_recv / (1024**2)

    return {
        'timestamp': datetime.now(),
        'cpu_percent': cpu_percent,
        'cpu_count': cpu_count,
        'memory_percent': memory_percent,
        'memory_used_gb': memory_used_gb,
        'memory_total_gb': memory_total_gb,
        'disk_percent': disk_percent,
        'disk_used_gb': disk_used_gb,
        'disk_total_gb': disk_total_gb,
        'bytes_sent_mb': bytes_sent_mb,
        'bytes_recv_mb': bytes_recv_mb,
    }

def check_thresholds(info, thresholds):
    """임계값 체크 및 알림"""

    alerts = []

    if info['cpu_percent'] > thresholds['cpu']:
        alerts.append(f"⚠️  CPU 사용률 높음: {info['cpu_percent']:.1f}%")

    if info['memory_percent'] > thresholds['memory']:
        alerts.append(f"⚠️  메모리 사용률 높음: {info['memory_percent']:.1f}%")

    if info['disk_percent'] > thresholds['disk']:
        alerts.append(f"⚠️  디스크 사용률 높음: {info['disk_percent']:.1f}%")

    return alerts

def monitor_system(interval=60, duration=None):
    """시스템 모니터링"""

    # 임계값 설정
    thresholds = {
        'cpu': 80,      # 80% 이상
        'memory': 85,   # 85% 이상
        'disk': 90,     # 90% 이상
    }

    print("🖥️  시스템 모니터링 시작")
    print(f"체크 간격: {interval}초")
    print(f"임계값 - CPU: {thresholds['cpu']}%, 메모리: {thresholds['memory']}%, 디스크: {thresholds['disk']}%")
    print("="*80)

    start_time = time.time()

    try:
        while True:
            # 시스템 정보 수집
            info = get_system_info()

            # 출력
            timestamp = info['timestamp'].strftime('%Y-%m-%d %H:%M:%S')
            print(f"\n[{timestamp}]")
            print(f"CPU: {info['cpu_percent']:.1f}% ({info['cpu_count']} cores)")
            print(f"메모리: {info['memory_percent']:.1f}% ({info['memory_used_gb']:.1f}GB / {info['memory_total_gb']:.1f}GB)")
            print(f"디스크: {info['disk_percent']:.1f}% ({info['disk_used_gb']:.1f}GB / {info['disk_total_gb']:.1f}GB)")
            print(f"네트워크: ↑{info['bytes_sent_mb']:.0f}MB ↓{info['bytes_recv_mb']:.0f}MB")

            # 알림 체크
            alerts = check_thresholds(info, thresholds)

            if alerts:
                print("\n🚨 알림:")
                for alert in alerts:
                    print(f"  {alert}")

                # 여기서 이메일, 텔레그램 등으로 알림 전송 가능
            else:
                print("✅ 정상 범위")

            # 종료 조건
            if duration and (time.time() - start_time) >= duration:
                print("\n⏹️  모니터링 종료")
                break

            # 대기
            time.sleep(interval)

    except KeyboardInterrupt:
        print("\n⏹️  사용자가 모니터링을 중지했습니다.")

# 실행
monitor_system(
    interval=10,      # 10초마다 체크
    duration=None     # 무한 실행 (Ctrl+C로 종료)
)
```

**🎯 활용 시나리오**:
- 서버 상태 모니터링
- 리소스 사용 추적
- 이상 징후 조기 발견

**💡 확장 아이디어**:
- 데이터베이스에 기록
- 그래프로 시각화
- 슬랙/텔레그램 알림 연동

---

## 21. 폴더 정리 자동화

**📝 설명**: 파일들을 확장자별로 자동 분류합니다.

**💻 전체 코드**:
```python
import os
import shutil
from pathlib import Path
from datetime import datetime
from collections import defaultdict

def organize_files(source_dir, organize_by='extension'):
    """파일 자동 정리"""

    # 파일 분류 규칙
    categories = {
        '이미지': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg', '.webp'],
        '문서': ['.pdf', '.doc', '.docx', '.txt', '.xlsx', '.pptx', '.hwp'],
        '비디오': ['.mp4', '.avi', '.mkv', '.mov', '.wmv'],
        '음악': ['.mp3', '.wav', '.flac', '.m4a'],
        '압축파일': ['.zip', '.rar', '.7z', '.tar', '.gz'],
        '코드': ['.py', '.js', '.java', '.cpp', '.html', '.css'],
        '기타': []
    }

    # 통계
    stats = defaultdict(int)
    moved_files = []

    print(f"📁 폴더 정리 시작: {source_dir}\n")

    # 파일 목록
    files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]

    print(f"정리할 파일: {len(files)}개")

    for filename in files:
        file_path = os.path.join(source_dir, filename)
        extension = Path(filename).suffix.lower()

        # 카테고리 결정
        category = '기타'
        for cat_name, extensions in categories.items():
            if extension in extensions:
                category = cat_name
                break

        # 목적지 폴더 생성
        dest_folder = os.path.join(source_dir, category)
        os.makedirs(dest_folder, exist_ok=True)

        # 파일 이동
        dest_path = os.path.join(dest_folder, filename)

        # 중복 파일명 처리
        if os.path.exists(dest_path):
            name, ext = os.path.splitext(filename)
            counter = 1
            while os.path.exists(dest_path):
                new_filename = f"{name}_{counter}{ext}"
                dest_path = os.path.join(dest_folder, new_filename)
                counter += 1

        # 이동
        shutil.move(file_path, dest_path)

        stats[category] += 1
        moved_files.append({
            '원본': filename,
            '카테고리': category,
            '위치': dest_path
        })

        print(f"  ✓ {filename} → {category}/")

    # 결과 출력
    print("\n" + "="*80)
    print("정리 완료!")
    print("="*80)

    for category, count in stats.items():
        print(f"{category}: {count}개 파일")

    # 로그 저장
    log_file = os.path.join(source_dir, f"organize_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
    with open(log_file, 'w', encoding='utf-8') as f:
        f.write(f"파일 정리 로그 - {datetime.now()}\n")
        f.write("="*80 + "\n\n")

        for item in moved_files:
            f.write(f"원본: {item['원본']}\n")
            f.write(f"카테고리: {item['카테고리']}\n")
            f.write(f"위치: {item['위치']}\n\n")

    print(f"\n로그 저장: {log_file}")

    return stats

# 실행
target_directory = "/Users/username/Downloads"
organize_files(target_directory)
```

**🎯 활용 시나리오**:
- 다운로드 폴더 자동 정리
- 프로젝트 파일 분류
- 중복 파일 제거

**💡 확장 아이디어**:
- 파일 생성/수정 날짜로 분류
- 파일 크기로 분류
- 스케줄러로 자동 실행

---

## 22. 텔레그램 알림봇

**📝 설명**: 텔레그램으로 자동 알림을 전송합니다.

**🔧 필요한 라이브러리**:
```bash
pip install python-telegram-bot==13.15
```

**💻 전체 코드**:
```python
from telegram import Bot, ParseMode
from datetime import datetime
import asyncio

class TelegramBot:
    """텔레그램 봇 클래스 (동기 방식)"""

    def __init__(self, token, chat_id):
        self.bot = Bot(token=token)
        self.chat_id = chat_id

    def send_message(self, text, parse_mode=ParseMode.MARKDOWN):
        """텍스트 메시지 전송"""
        try:
            self.bot.send_message(
                chat_id=self.chat_id,
                text=text,
                parse_mode=parse_mode
            )
            print(f"✅ 메시지 전송 완료: {text[:50]}...")
            return True
        except Exception as e:
            print(f"❌ 메시지 전송 실패: {e}")
            return False

    def send_document(self, file_path, caption=""):
        """파일 전송"""
        try:
            with open(file_path, 'rb') as file:
                self.bot.send_document(
                    chat_id=self.chat_id,
                    document=file,
                    caption=caption
                )
            print(f"✅ 파일 전송 완료: {file_path}")
            return True
        except Exception as e:
            print(f"❌ 파일 전송 실패: {e}")
            return False

    def send_photo(self, photo_path, caption=""):
        """사진 전송"""
        try:
            with open(photo_path, 'rb') as photo:
                self.bot.send_photo(
                    chat_id=self.chat_id,
                    photo=photo,
                    caption=caption
                )
            print(f"✅ 사진 전송 완료: {photo_path}")
            return True
        except Exception as e:
            print(f"❌ 사진 전송 실패: {e}")
            return False

# 사용 예시
def daily_notification():
    """일일 알림"""

    # 봇 초기화
    token = "YOUR_BOT_TOKEN"
    chat_id = "YOUR_CHAT_ID"
    bot = TelegramBot(token, chat_id)

    # 알림 메시지
    message = f"""
🌅 *일일 업무 알림*

📅 날짜: {datetime.now().strftime('%Y년 %m월 %d일')}
⏰ 시간: {datetime.now().strftime('%H:%M:%S')}

✅ *오늘의 작업*
• 보고서 작성
• 미팅 준비
• 이메일 확인

💪 화이팅!
    """

    bot.send_message(message)

def error_notification(error_message):
    """에러 알림"""

    token = "YOUR_BOT_TOKEN"
    chat_id = "YOUR_CHAT_ID"
    bot = TelegramBot(token, chat_id)

    message = f"""
🚨 *에러 발생!*

시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

에러 내용:
```
{error_message}
```

즉시 확인이 필요합니다!
    """

    bot.send_message(message)

def send_daily_report(report_file):
    """일일 보고서 전송"""

    token = "YOUR_BOT_TOKEN"
    chat_id = "YOUR_CHAT_ID"
    bot = TelegramBot(token, chat_id)

    # 먼저 메시지 전송
    bot.send_message(f"📊 *일일 보고서* ({datetime.now().strftime('%Y-%m-%d')})")

    # 파일 전송
    bot.send_document(report_file, caption="상세 내용은 첨부 파일을 확인하세요.")

# 실행
if __name__ == "__main__":
    daily_notification()
```

**💡 Bot Token과 Chat ID 얻는 방법**:
1. **Bot Token 얻기**:
   - 텔레그램에서 [@BotFather](https://t.me/botfather) 검색
   - `/newbot` 명령어로 새 봇 생성
   - Bot Token 복사

2. **Chat ID 얻기**:
   - 봇과 대화 시작 (메시지 1개 전송)
   - 브라우저에서 `https://api.telegram.org/bot<YOUR_BOT_TOKEN>/getUpdates` 접속
   - `"chat":{"id":12345678}` 형식에서 숫자 확인
```

**🎯 활용 시나리오**:
- 작업 완료 알림
- 시스템 에러 알림
- 일일 보고서 전송

**💡 확장 아이디어**:
- 명령어 기반 봇 (사용자 명령 처리)
- 대화형 봇 (AI 연동)
- 그룹 채팅 관리 봇

---

# 🎯 마무리

이 문서의 모든 예시는 실제 작동하는 코드입니다. 각 예시를 참고하여:

1. **자신의 환경에 맞게 수정**하세요 (API 키, 파일 경로 등)
2. **작은 부분부터 테스트**하세요
3. **에러가 발생하면 AI(Claude)에게 물어보세요**
4. **성공한 코드는 저장하고 재사용**하세요

**더 많은 활용 사례가 필요하다면?**
- Python 공식 문서 참고
- GitHub에서 오픈소스 프로젝트 검색
- AI에게 구체적인 상황 설명하고 코드 요청

**Happy Coding! 🚀**
