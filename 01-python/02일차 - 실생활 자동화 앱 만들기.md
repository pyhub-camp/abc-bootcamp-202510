# 02일차 - 실생활 자동화 앱 만들기

> **🎯 오늘의 목표**: 실제 생활에서 사용할 수 있는 QR 코드 생성기와 뉴스 크롤러를 AI와 함께 만듭니다!

```table-of-contents
```

---

# 🌟 오늘 무엇을 만들까요?

## 완성 화면 미리보기

**프로젝트 1: QR 코드 생성기** (11:30 완성 목표)
```
━━━━━━━━━━━━━━━━━━
📱 QR 코드 생성기
━━━━━━━━━━━━━━━━━━

URL 또는 텍스트 입력:
┌─────────────────┐
│https://naver.com│
└─────────────────┘

     [QR 코드 생성]

━━━━━━━━━━━━━━━━━━
     [QR CODE]
     ███████████
     ██ ▄▄▄ ██
     ██ ███ ██
     ███████████

   [이미지 다운로드]
━━━━━━━━━━━━━━━━━━
```

**프로젝트 2: 뉴스 헤드라인 크롤러** (16:30 완성 목표)
```
━━━━━━━━━━━━━━━━━━
📰 네이버 뉴스 헤드라인
━━━━━━━━━━━━━━━━━━

카테고리: [정치▼] [수집하기]

━━━━━━━━━━━━━━━━━━
🔥 TOP 10 뉴스
━━━━━━━━━━━━━━━━━━

1. 대통령, 국회 시정연설...
2. 한은 기준금리 동결...
3. 반도체 수출 호조세...

[CSV로 저장]
━━━━━━━━━━━━━━━━━━
✅ 10개 뉴스 수집 완료!
```

---

## 왜 이 도구들을 사용하나요?

> **💡 도구 선택 철학**:
> "모든 도구는 AI가 추천해줄 수 있어요!"
> 하지만 **왜 이 도구인지** 이해하면 더 똑똑하게 AI와 대화할 수 있습니다.

### 📦 오늘 사용할 주요 라이브러리

#### 1. qrcode - QR 코드 생성

**왜 이 라이브러리를 선택했나요?**
```
✅ 장점:
- 순수 파이썬 라이브러리 (추가 설치 없음)
- 사용법이 매우 간단
- 한글 완벽 지원
- 커스터마이징 자유도 높음

📊 대안 비교:
- qrcode (★★★★★) - 오늘의 선택!
  → 가장 인기 있고 문서화 잘됨
- segno (★★★★☆)
  → 더 많은 기능, 약간 복잡함
- pyqrcode (★★★☆☆)
  → 더 가볍지만 기능 제한적
```

**다른 라이브러리로 바꿀 수 있나요?**
```python
# qrcode → segno로 변경 예시
# qrcode 방식:
import qrcode
qr = qrcode.QRCode()
qr.add_data("https://naver.com")
img = qr.make_image()

# segno 방식:
import segno
qr = segno.make("https://naver.com")
qr.save("qrcode.png")

💬 AI에게 물어보기:
"qrcode 대신 segno 라이브러리로 바꾸고 싶어.
현재 코드를 segno로 변환해줘."
```

---

#### 2. requests - 웹 페이지 요청

**왜 이 라이브러리를 선택했나요?**
```
✅ 장점:
- 파이썬 웹 요청의 표준
- 사용법이 직관적 ("Human-Friendly")
- 에러 처리가 쉬움
- 대부분의 AI가 잘 알고 있음

📊 대안 비교:
- requests (★★★★★) - 오늘의 선택!
  → 가장 인기, 초보자 친화적
- httpx (★★★★☆)
  → 비동기 지원, 최신 라이브러리
- urllib (★★★☆☆)
  → 파이썬 내장, 하지만 사용법 복잡
```

**다른 라이브러리로 바꿀 수 있나요?**
```python
# requests → httpx로 변경 예시
# requests 방식:
import requests
response = requests.get(url, timeout=10)
html = response.text

# httpx 방식:
import httpx
response = httpx.get(url, timeout=10)
html = response.text

💬 AI에게 물어보기:
"requests 대신 httpx로 바꾸고 싶어.
비동기 처리도 추가해줘."
```

---

#### 3. BeautifulSoup - HTML 파싱

**왜 이 라이브러리를 선택했나요?**
```
✅ 장점:
- HTML 파싱의 표준 도구
- CSS 셀렉터 지원 (웹 개발 경험 활용)
- 에러에 관대함 (망가진 HTML도 처리)
- 학습 자료가 풍부

📊 대안 비교:
- BeautifulSoup (★★★★★) - 오늘의 선택!
  → 가장 초보자 친화적
- lxml (★★★★☆)
  → 더 빠르지만 설치 복잡
- Scrapy (★★★★☆)
  → 대규모 크롤링용 프레임워크
- Selenium (★★★★☆)
  → JavaScript 실행 필요시
```

**다른 라이브러리로 바꿀 수 있나요?**
```python
# BeautifulSoup → lxml로 변경 예시
# BeautifulSoup 방식:
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'html.parser')
headlines = soup.select('.sh_text')

# lxml 방식:
from lxml import html as lhtml
tree = lhtml.fromstring(html)
headlines = tree.cssselect('.sh_text')

💬 AI에게 물어보기:
"BeautifulSoup 대신 lxml로 바꿔서
속도를 개선하고 싶어."
```

---

### 🔄 언어와 환경 전환

#### 다른 프로그래밍 언어로 바꾼다면?

**Node.js로 변환**:
```javascript
// Python: qrcode
import qrcode
qr = qrcode.QRCode()

// JavaScript: qrcode 패키지
const QRCode = require('qrcode');
QRCode.toDataURL('https://naver.com');

💬 AI에게 물어보기:
"이 파이썬 코드를 Node.js로 변환해줘.
npm 패키지도 알려줘."
```

**Go로 변환**:
```go
// Python: requests + BeautifulSoup
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

// Go: net/http + goquery
resp, _ := http.Get(url)
doc, _ := goquery.NewDocumentFromReader(resp.Body)

💬 AI에게 물어보기:
"웹 크롤러를 Go 언어로 변환하고
goroutine으로 병렬 처리 추가해줘."
```

---

### 🎯 실전 상황별 도구 선택

#### 상황 1: JavaScript로 작성된 웹사이트 크롤링

**문제**: BeautifulSoup으로 안 보이는 데이터
```python
# BeautifulSoup → Selenium으로 변경
from selenium import webdriver
from selenium.webdriver.common.by import By

driver = webdriver.Chrome()
driver.get(url)
# JavaScript 실행 대기
driver.implicitly_wait(10)
headlines = driver.find_elements(By.CSS_SELECTOR, '.sh_text')

💬 AI에게 물어보기:
"JavaScript로 렌더링되는 페이지라서
BeautifulSoup으로 데이터를 못 가져와.
Selenium으로 변환해줘."
```

#### 상황 2: 대량의 QR 코드 빠르게 생성

**문제**: 1000개 QR 코드 생성 속도
```python
# qrcode → segno (더 빠른 라이브러리)
import segno
from multiprocessing import Pool

def make_qr(data):
    qr = segno.make(data)
    qr.save(f"qr_{data}.png")

# 병렬 처리로 속도 10배 향상
with Pool(8) as p:
    p.map(make_qr, url_list)

💬 AI에게 물어보기:
"1000개 QR 코드를 빠르게 생성하고 싶어.
멀티프로세싱으로 병렬 처리해줘."
```

#### 상황 3: 크롤링 차단 우회

**문제**: 403 Forbidden 에러
```python
# requests → requests + headers
import requests

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
    'Accept': 'text/html,application/xhtml+xml',
}
response = requests.get(url, headers=headers)

💬 AI에게 물어보기:
"웹사이트에서 403 에러가 나. requests 헤더에
User-Agent랑 필요한 정보 추가해줘."
```

---

### ✅ 도구 선택 체크리스트

**라이브러리 바꾸고 싶을 때**:
- [ ] 현재 라이브러리의 문제점이 명확한가?
- [ ] 대안 라이브러리의 장점을 이해했나?
- [ ] AI에게 구체적인 변환 요청을 할 수 있나?

**AI에게 물어볼 때**:
```
✅ 좋은 질문:
"requests 대신 httpx를 쓰면 어떤 장점이 있어?
현재 코드를 httpx로 변환하는 예시 보여줘."

❌ 나쁜 질문:
"더 좋은 라이브러리 알려줘"
```

---

### 💡 핵심 철학

**1. 도구는 목적의 수단**
```
QR 코드를 만드는 게 목표 (O)
qrcode 라이브러리 쓰는 게 목표 (X)

→ 목표 달성에 도구가 방해되면 바꾸세요!
```

**2. AI는 도구 전환의 비서**
```
라이브러리 바꾸기 = 10초
AI에게 "X에서 Y로 변환해줘" 한 마디면 됩니다.

→ 도구에 갇히지 마세요!
```

**3. 상황에 맞는 최적 도구**
```
초보자 학습: qrcode, requests, BeautifulSoup
속도 중요: segno, httpx, lxml
JavaScript 사이트: Selenium
대규모 크롤링: Scrapy

→ 상황별로 AI에게 물어보세요!
```

---

# 🔄 어제 복습 (09:00-09:30)

## 간단 퀴즈

**Q1. Streamlit 앱을 실행하는 명령어는?**
<details>
<summary>정답 보기</summary>

```bash
streamlit run app.py
```
</details>

**Q2. 사용자 입력을 받는 함수는?**
<details>
<summary>정답 보기</summary>

```python
st.text_input("라벨")
st.number_input("라벨")
```
</details>

**Q3. 버튼을 만드는 함수는?**
<details>
<summary>정답 보기</summary>

```python
if st.button("버튼"):
    # 클릭 시 실행할 코드
```
</details>

---

## 어제 만든 앱 개선하기 (선택)

**시간이 있다면**:
```
"어제 만든 인사말 생성기에 '좋아하는 음식' 입력도 추가해줘"
"생성된 인사말을 더 길고 재미있게 만들어줘"
```

---

# 📱 프로젝트 1: QR 코드 생성기 (09:30-11:30)

## Step 1: 오늘의 목표 이해하기 (10분)

### 왜 QR 코드 생성기인가?

**실생활 활용**:
- 📱 명함에 연락처/SNS QR 코드
- 🎫 행사 초대장 링크
- 📦 제품 정보 페이지
- 💰 계좌번호/송금 링크

**학습 포인트**:
- 파일 생성 및 저장
- 이미지 처리 라이브러리
- 다운로드 기능 구현

---

## Step 2: AI와 함께 코드 만들기 (30분)

### 📂 작업 폴더 준비

```bash
# Windows
cd C:\Work\abc-bootcamp-202510\day2
code .

# Mac
cd /Users/사용자명/Work/abc-bootcamp-202510/day2
code .
```

**폴더 구조**:
```
C:\Work\abc-bootcamp-202510\day2\
├── qr_generator.py      # QR 코드 생성기
└── news_crawler.py      # 뉴스 크롤러 (오후에 생성)
```

---

### 🤖 AI에게 요청하기

**VSCode에서 새 파일 생성**: `qr_generator.py`

**AI 프롬프트**:
```
Streamlit으로 QR 코드 생성기를 만들어줘.

요구사항:
1. 사용자가 URL이나 텍스트를 입력
2. "QR 코드 생성" 버튼 클릭
3. QR 코드 이미지를 화면에 표시
4. 이미지 다운로드 버튼 제공

라이브러리: qrcode, pillow, streamlit
```

---

### 💡 AI가 생성한 코드 예시

```python
import streamlit as st
import qrcode
from io import BytesIO

st.title("📱 QR 코드 생성기")

# 입력
text = st.text_input("URL 또는 텍스트 입력",
                     placeholder="https://naver.com")

if st.button("QR 코드 생성"):
    if text:
        # QR 코드 생성
        qr = qrcode.QRCode(
            version=1,
            box_size=10,
            border=4
        )
        qr.add_data(text)
        qr.make(fit=True)

        # 이미지로 변환
        img = qr.make_image(fill_color="black", back_color="white")

        # Streamlit에 표시
        st.image(img, caption="생성된 QR 코드")

        # 다운로드 버튼
        buffer = BytesIO()
        img.save(buffer, format="PNG")
        st.download_button(
            label="이미지 다운로드",
            data=buffer.getvalue(),
            file_name="qrcode.png",
            mime="image/png"
        )
    else:
        st.warning("텍스트를 입력하세요!")
```

---

### 📦 라이브러리 설치

**터미널에서**:
```bash
pip install qrcode pillow
```

**확인**:
```bash
pip show qrcode
pip show pillow
```

> 💡 **설치 확인**: `pip show` 명령어는 패키지 정보를 보여줍니다. 설치되지 않았으면 에러가 나옵니다.

---

### 🚀 실행하기

```bash
streamlit run qr_generator.py
```

**브라우저에서 확인**: http://localhost:8501

---

## Step 3: 코드 이해하기 (20분)

### 🧩 코드 분석

**1. QR 코드 생성**:
```python
qr = qrcode.QRCode(
    version=1,      # QR 코드 크기 (1~40)
    box_size=10,    # 각 박스 픽셀 크기
    border=4        # 테두리 두께
)
qr.add_data(text)   # 데이터 추가
qr.make(fit=True)   # 최적 크기로 생성
```

**2. 이미지 변환**:
```python
img = qr.make_image(fill_color="black", back_color="white")
```

**3. 메모리 버퍼 사용**:
```python
buffer = BytesIO()    # 메모리에 임시 저장
img.save(buffer, format="PNG")
buffer.getvalue()     # 바이트 데이터 가져오기
```

**4. 다운로드 버튼**:
```python
st.download_button(
    label="이미지 다운로드",
    data=buffer.getvalue(),
    file_name="qrcode.png",
    mime="image/png"
)
```

---

### 📝 함께 적어보기

**선생님과 함께 주석 달기**:
```python
# 사용자 입력 받기
text = st.text_input(...)

# 버튼 클릭 시
if st.button(...):
    # QR 코드 객체 생성
    qr = qrcode.QRCode(...)

    # 데이터 넣기
    qr.add_data(text)

    # 이미지로 만들기
    img = qr.make_image(...)

    # 화면에 보여주기
    st.image(img)
```

---

## Step 4: 디버깅으로 코드 속 들여다보기 (20분)

### 🔍 디버깅 목표

QR 코드가 어떻게 생성되는지 단계별로 확인해봅시다!

---

### 🐛 디버깅 코드 추가

```python
import streamlit as st
import qrcode
from io import BytesIO

st.title("📱 QR 코드 생성기")

text = st.text_input("URL 또는 텍스트 입력",
                     placeholder="https://naver.com")

# 🔍 디버깅: 입력값 확인
st.write(f"🔍 DEBUG - 입력 텍스트: '{text}'")
st.write(f"🔍 DEBUG - 텍스트 길이: {len(text)}자")
st.write(f"🔍 DEBUG - 비어있나? {text == ''}")

if st.button("QR 코드 생성"):
    if text:
        # 🔍 디버깅: QR 코드 설정 확인
        st.write("🔍 DEBUG - QR 코드 객체 생성 중...")

        qr = qrcode.QRCode(version=1, box_size=10, border=4)

        # 🔍 디버깅: QR 코드 객체 정보
        st.write(f"🔍 DEBUG - QR 버전: {qr.version}")
        st.write(f"🔍 DEBUG - 박스 크기: {qr.box_size}px")

        qr.add_data(text)
        qr.make(fit=True)

        # 🔍 디버깅: 최종 QR 코드 크기
        st.write(f"🔍 DEBUG - 최종 버전: {qr.version}")
        st.write(f"🔍 DEBUG - 데이터 모드: {qr.mode}")

        img = qr.make_image(fill_color="black", back_color="white")

        # 🔍 디버깅: 이미지 정보
        st.write(f"🔍 DEBUG - 이미지 크기: {img.size}")
        st.write(f"🔍 DEBUG - 이미지 모드: {img.mode}")

        st.image(img, caption="생성된 QR 코드")

        buffer = BytesIO()
        img.save(buffer, format="PNG")

        # 🔍 디버깅: 파일 크기
        file_size = len(buffer.getvalue())
        st.write(f"🔍 DEBUG - 파일 크기: {file_size:,} bytes ({file_size/1024:.2f} KB)")

        st.download_button(
            label="이미지 다운로드",
            data=buffer.getvalue(),
            file_name="qrcode.png",
            mime="image/png"
        )
    else:
        st.warning("텍스트를 입력하세요!")
```

---

### 🎯 디버깅 실습

**실험 1: 짧은 URL vs 긴 URL**
```
짧은 URL: https://naver.com
긴 URL: https://www.naver.com/search?query=파이썬+streamlit+qrcode+생성기+만들기

QR 코드 버전이 어떻게 달라지나요?
이미지 크기는 어떻게 변하나요?
```

**실험 2: 한글 텍스트**
```
입력: 안녕하세요! 파이썬 부트캠프입니다.

파일 크기가 영문과 비교해서 어떤가요?
QR 코드가 복잡해졌나요?
```

**실험 3: 빈 입력**
```
아무것도 입력하지 않고 버튼 클릭

디버그 메시지에서 무엇이 보이나요?
경고 메시지가 제대로 나오나요?
```

---

### 🐛 버그 수정 실습

**버그 코드**:
```python
# 🐛 버그: 한글이 깨집니다!
text = st.text_input("텍스트 입력")

if st.button("생성"):
    # 잘못된 인코딩
    qr = qrcode.QRCode()
    qr.add_data(text.encode('cp949'))  # ❌ 잘못된 인코딩
    qr.make()
    img = qr.make_image()
    st.image(img)
```

**AI에게 질문**:
```
"한글을 QR 코드로 만들 때 깨지는데 어떻게 해결하나요?"
```

**올바른 코드**:
```python
# ✅ UTF-8이 기본값이므로 별도 인코딩 불필요
qr.add_data(text)  # 그냥 이렇게!
```

---

### 💡 배운 점 정리

**Q: QR 코드 버전이 자동으로 커지는 이유는?**
```
A: 데이터가 많을수록 더 복잡한 QR 코드 필요
   fit=True 옵션이 자동으로 최적 크기 선택
```

**Q: BytesIO는 왜 사용하나요?**
```
A: 파일을 디스크에 저장하지 않고 메모리에서 처리
   다운로드 버튼에 바로 전달 가능
```

---

### 🎯 나의 언어로 정리하기 (파인만 기법)

> **왜 이 방법이 중요한가?**: QR 코드 생성 같은 새로운 기술은 단순 암기로는 부족합니다.
> 내 언어로 설명할 수 있어야 진짜 이해한 겁니다!

#### 📝 실습: QR 코드 생성 과정 설명해보기

**Step 1: 나만의 방식으로 써보기** (5분)

친구에게 설명한다고 생각하고 써보세요:
```
QR 코드가 어떻게 만들어지는지 내가 이해한 내용:

"URL이나 텍스트를 입력하면..."
"qrcode.QRCode()는..."
"BytesIO는..."

✍️ [여기에 자유롭게 작성]
```

**Step 2: AI와 검증하기** (5-10분)

💬 AI에게 이렇게 질문:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
QR 코드 생성 과정에 대해 내가 이해한 내용이야:

"[위에서 작성한 내용을 여기에 복사-붙여넣기]"

이 설명이 정확해? 틀린 부분이나 빠진 개념 있어?
초보자가 이해하기 쉽게 비유도 들어줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**Step 3: 수정하고 재정리** (3분)

AI 피드백을 반영해서 다시 써보세요:
```
[수정된 설명]
```

---

#### 🎯 즉시 미션

다음 중 하나를 선택해서 "나의 언어로 설명하기":

**옵션 A**: `qr.make(fit=True)`가 하는 일
```
내 설명: "fit=True는..."
```

**옵션 B**: `BytesIO`의 역할
```
내 설명: "BytesIO는 메모리에서..."
```

**옵션 C**: `st.download_button()`이 작동하는 원리
```
내 설명: "다운로드 버튼은..."
```

---

#### 💡 학습 효과 비교

| 방법 | 이해도 | 기억 지속력 | 응용력 |
|------|--------|------------|--------|
| 그냥 코드 따라하기 | 30% | 1주일 | 낮음 |
| 코드 읽고 이해하기 | 60% | 2주일 | 보통 |
| **나의 언어로 정리** | 90% | 1개월+ | 높음 |

---

## Step 5: 기능 추가하기 (30분)

### 🎨 개선 아이디어

**AI에게 요청해보세요**:

**1. QR 코드 색상 변경**:
```
"QR 코드의 색상을 사용자가 선택할 수 있게 해줘.
색상 선택기(color picker)를 추가해줘."
```

**2. 크기 조절**:
```
"QR 코드 크기를 슬라이더로 조절할 수 있게 해줘.
box_size를 5~20 사이로 조절하도록."
```

**3. 여러 개 생성**:
```
"여러 개의 URL을 한 번에 입력받아서
각각의 QR 코드를 생성하고
ZIP 파일로 다운로드할 수 있게 해줘."
```

**4. 로고 추가**:
```
"QR 코드 중앙에 작은 이미지를 넣을 수 있게 해줘.
사용자가 이미지를 업로드하면 QR 코드에 추가되도록."
```

---

### 💻 개선된 코드 예시

```python
import streamlit as st
import qrcode
from io import BytesIO

st.title("📱 QR 코드 생성기 Pro")

# 입력
text = st.text_input("URL 또는 텍스트", placeholder="https://naver.com")

# 색상 선택
col1, col2 = st.columns(2)
with col1:
    fill_color = st.color_picker("QR 코드 색상", "")
with col2:
    back_color = st.color_picker("배경 색상", "")

# 크기 조절
box_size = st.slider("QR 코드 크기", 5, 20, 10)

if st.button("QR 코드 생성"):
    if text:
        qr = qrcode.QRCode(version=1, box_size=box_size, border=4)
        qr.add_data(text)
        qr.make(fit=True)

        img = qr.make_image(fill_color=fill_color, back_color=back_color)

        st.image(img, caption="생성된 QR 코드")

        buffer = BytesIO()
        img.save(buffer, format="PNG")
        st.download_button(
            label="이미지 다운로드",
            data=buffer.getvalue(),
            file_name="qrcode.png",
            mime="image/png"
        )
```

---

## Step 6: 네트워크로 공유하기 (10분)

### 🌐 같은 반 친구들과 공유

**네트워크 공유로 실행**:
```bash
streamlit run qr_generator.py --server.address 0.0.0.0
```

**내 IP 주소 확인**:
```bash
# Windows
ipconfig

# Mac
ipconfig getifaddr en0
```

**친구들 접속**:
```
http://[내-IP주소]:8501

예: http://192.168.0.123:8501
```

---

### 🎯 공유 미션

**2인 1조 활동** (10분):
1. A가 QR 코드 생성기 공유
2. B가 A의 앱 접속
3. B가 자신의 SNS 링크로 QR 코드 생성
4. 생성된 QR 코드를 스마트폰으로 스캔
5. 역할 바꿔서 반복

**재미있는 QR 코드 만들어보기**:
- YouTube 영상 링크
- 카카오톡 오픈채팅방
- Google Forms 설문
- 본인 포트폴리오 사이트

---

## Step 7: 나만의 QR 코드 앱 만들기 (20분)

### 🎯 내 문제, 내가 해결하기

> **핵심 질문**: "이 QR 코드를 **실제로 어디에** 사용할 건가요?"

**질문 1: QR 코드가 필요한 순간은?**
```
예시:
- 내 인스타그램 공유 (친구들에게)
- 우리 반 단톡방 초대 (신입생용)
- 집 와이파이 접속 (손님용)
- 내가 좋아하는 유튜브 채널 공유

✍️ [실제로 사용할 용도 1개 정하기]
```

**질문 2: 어떻게 바꾸면 더 유용할까?**
```
내 용도: "인스타그램 QR 코드"

추가하고 싶은 기능:
- QR 코드 색상 바꾸기 (분홍색!)
- 내 닉네임 표시하기
- 여러 개 한번에 만들기 (친구들 것도)

💭 [AI에게 어떻게 요청할지 생각해보기]
```

---

### 🤖 AI와 함께 커스터마이징

> **💡 핵심 전략**: 애매하게 물어보면 애매한 답만 나옵니다.
> SETUP 구조로 구체적으로 요청하면 **정확한 코드**를 받습니다!

---

#### 📋 1단계: 기본 기능 추가 (복사-붙여넣기 프롬프트)

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[SETUP]
- 상황: 현재 QR 코드 생성기가 있어요
- 목표: 사용자가 QR 코드 색상과 크기를 선택할 수 있게 만들기
- 입력: 텍스트 입력은 그대로 유지
- 출력: 색상과 크기가 적용된 QR 코드 PNG 파일
- 제약사항: qrcode, streamlit, pillow 라이브러리만 사용
- 코드 스타일: 기존 코드 구조 유지, 주석은 한글로

[YOUR TASK]
현재 QR 코드 생성 코드에 다음 기능을 추가해줘:

1. **색상 선택 기능**
   - st.color_picker()로 QR 코드 전경색(fill_color) 선택
   - 기본값: 검은색()
   - 배경색(back_color)은 흰색 고정

2. **크기 선택 기능**
   - st.slider()로 QR 코드 크기(box_size) 선택
   - 범위: 5~15
   - 기본값: 10

3. **미리보기 개선**
   - 생성된 QR 코드를 st.image()로 표시
   - 다운로드 버튼도 유지

현재 코드를 수정해서 완전한 코드를 보여줘.
주석으로 어떤 부분이 바뀌었는지 표시해줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**📌 복사 팁**: 위 박스 전체를 복사해서 AI(ChatGPT, Claude)에 붙여넣기!

---

#### 📋 2단계: 고급 기능 추가 (복사-붙여넣기 프롬프트)

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[SETUP]
- 상황: 1단계 코드가 완성되었어요
- 목표: 여러 개 URL을 한번에 QR 코드로 만들기
- 입력: 텍스트 여러 줄 입력 (줄바꿈으로 구분)
- 출력: ZIP 파일로 모든 QR 코드를 한번에 다운로드
- 제약사항: zipfile, datetime 추가 사용 가능
- 코드 스타일: 기존 색상/크기 선택 기능 유지

[YOUR TASK]
1단계 코드에 다음 기능을 추가해줘:

1. **여러 줄 입력**
   - st.text_area()로 변경
   - 줄바꿈으로 여러 URL 구분
   - 빈 줄은 무시

2. **일괄 생성**
   - 각 줄마다 QR 코드 생성
   - 파일명은 자동으로 "qr_1.png", "qr_2.png" 등

3. **ZIP 다운로드**
   - 생성된 모든 QR 코드를 ZIP으로 압축
   - 파일명: "qr_codes_YYYYMMDD_HHMMSS.zip"
   - 다운로드 버튼 제공

4. **진행 상황 표시**
   - st.progress()로 진행률 표시
   - "3개 중 1개 생성 완료..." 같은 메시지

완전한 코드를 보여주고, 새로 추가된 부분에 # [NEW] 주석 표시해줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

---

#### 📋 3단계: 실전 응용 (나만의 용도 프롬프트 만들기)

**나만의 프롬프트 작성 템플릿**:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[SETUP]
- 상황: [내가 만든 QR 코드 앱 설명]
- 목표: [구체적인 목표 - 예: 명함용 QR, WiFi QR 등]
- 입력: [어떤 정보를 입력받을지]
- 출력: [어떤 형태로 결과를 보여줄지]
- 제약사항: [사용할 라이브러리, 제한사항]
- 코드 스타일: [원하는 스타일]

[YOUR TASK]
[구체적인 기능 요청 1]
[구체적인 기능 요청 2]
[구체적인 기능 요청 3]

완전한 코드를 보여주고, 주석으로 설명해줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**💡 실전 예시 - WiFi QR 코드 생성기**:
```
[SETUP]
- 상황: QR 코드 생성기가 있어요
- 목표: 스캔하면 자동으로 WiFi에 연결되는 QR 코드 만들기
- 입력: WiFi 이름(SSID), 비밀번호, 보안 타입(WPA/WEP/없음)
- 출력: WiFi 연결 정보가 담긴 QR 코드 PNG 파일
- 제약사항: qrcode, streamlit 라이브러리만 사용
- 코드 스타일: 주석 한글, 변수명 영어

[YOUR TASK]
WiFi 연결 QR 코드 생성 앱을 만들어줘:

1. WiFi 정보 입력 받기
   - SSID: 텍스트 입력
   - 비밀번호: 텍스트 입력 (st.text_input type="password")
   - 보안 타입: 선택 박스 (WPA, WEP, nopass)

2. WiFi QR 코드 형식으로 변환
   - 형식: "WIFI:T:{보안타입};S:{SSID};P:{비밀번호};;"
   - 예시: "WIFI:T:WPA;S:MyWiFi;P:password123;;"

3. QR 코드 생성 및 다운로드
   - 생성된 QR 코드 미리보기
   - PNG 파일 다운로드 버튼

완전한 코드를 보여주고, 각 부분에 설명 주석 추가해줘.
```

---

#### ✅ AI 응답 검증 체크리스트

AI가 준 코드를 실행하기 전에 확인:
- [ ] 필요한 라이브러리가 모두 import 되었나요?
- [ ] 함수나 변수명이 이해하기 쉬운가요?
- [ ] 에러 처리(try-except)가 있나요?
- [ ] 주석으로 설명이 충분한가요?
- [ ] 내가 요청한 기능이 모두 포함되었나요?

**문제가 있다면 이렇게 물어보세요**:
```
"위 코드에서 [구체적인 문제]가 있어.
[어떻게 동작해야 하는지]로 수정해줘."
```

---

### 💡 추천 커스터마이징 아이디어

**레벨 1: 간단 (10분)**
```
- QR 코드 크기 조절 (slider)
- QR 코드 테두리 두께 변경
- 생성한 시각 표시
```

**레벨 2: 보통 (15분)**
```
- QR 코드 색상 선택 (color_picker)
- 여러 개 URL 입력받아서 한번에 생성
- 생성 히스토리 표시 (세션 상태)
```

**레벨 3: 도전 (20분+)**
```
- 로고 이미지 추가 (QR 코드 중앙에)
- 단축 URL 자동 생성 (bitly API)
- QR 코드에 설명 텍스트 추가
```

---

### ✅ 완성 체크

**질문**:
- [ ] 내가 정한 용도에 맞게 수정했나요?
- [ ] AI에게 구체적으로 요청했나요?
- [ ] 실제로 사용해볼 수 있나요?
- [ ] 다른 사람에게 설명할 수 있나요?

**중요**:
```
💡 "남이 시킨 과제"가 아니라
   "내가 필요해서 만든 앱"이 되었나요?
```

---

# 📰 프로젝트 2: 뉴스 헤드라인 크롤러 (13:00-16:30)

## Step 1: 크롤링이란? (20분)

### 🌐 웹 크롤링 개념

**크롤링 (Web Crawling)**:
- 웹 페이지의 데이터를 자동으로 수집
- HTML 구조 분석 → 원하는 정보 추출
- 뉴스, 날씨, 주식, 제품 정보 등

**실생활 활용**:
- 📰 뉴스 모니터링
- 💰 가격 비교
- 📊 데이터 수집 자동화
- 🔍 검색 엔진

---

### ⚠️ 크롤링 주의사항

**1. 로봇 배제 표준 확인**:
```
https://www.naver.com/robots.txt
→ 크롤링 허용 여부 확인
```

**2. 과도한 요청 자제**:
- 서버에 부담 주지 않기
- 요청 간격 두기 (time.sleep)

**3. 저작권 존중**:
- 개인 학습용으로만 사용
- 상업적 이용 제한 (사이트 정책 확인 필요)

---

## Step 2: AI와 함께 크롤러 만들기 (40분)

### 📂 새 파일 생성

**VSCode에서**: `news_crawler.py`

---

### 🤖 AI 프롬프트

```
Streamlit과 BeautifulSoup으로 네이버 뉴스 헤드라인 크롤러를 만들어줘.

요구사항:
1. 네이버 뉴스 정치 섹션에서 헤드라인 수집
2. 제목과 링크를 표시
3. 수집한 뉴스를 리스트로 보여주기
4. CSV 파일로 저장 기능

라이브러리: requests, beautifulsoup4, streamlit, pandas
```

---

### 💡 AI가 생성한 코드 예시

```python
import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd

st.title("📰 네이버 뉴스 헤드라인 크롤러")

# 카테고리 선택
category = st.selectbox(
    "뉴스 카테고리",
    ["정치", "경제", "사회", "생활/문화", "IT/과학"]
)

category_code = {
    "정치": "100",
    "경제": "101",
    "사회": "102",
    "생활/문화": "103",
    "IT/과학": "105"
}

if st.button("뉴스 수집하기"):
    with st.spinner("뉴스 수집 중..."):
        # URL 생성
        url = f"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1={category_code[category]}"

        # 요청
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')

        # 뉴스 제목 추출
        headlines = soup.select('.sh_text')

        news_list = []
        for idx, headline in enumerate(headlines[:10], 1):
            title = headline.text.strip()
            link = headline['href']
            news_list.append({
                "순번": idx,
                "제목": title,
                "링크": link
            })

        # 결과 표시
        st.success(f"✅ {len(news_list)}개 뉴스 수집 완료!")

        for news in news_list:
            st.write(f"**{news['순번']}. {news['제목']}**")
            st.write(f"🔗 {news['링크']}")
            st.divider()

        # CSV 저장
        df = pd.DataFrame(news_list)
        csv = df.to_csv(index=False).encode('utf-8-sig')

        st.download_button(
            label="CSV 다운로드",
            data=csv,
            file_name=f"news_{category}.csv",
            mime="text/csv"
        )
```

---

### 📦 라이브러리 설치

```bash
pip install requests beautifulsoup4 pandas
```

---

### 🚀 실행하기

```bash
streamlit run news_crawler.py
```

---

## Step 3: 디버깅으로 크롤링 이해하기 (30분)

### 🔍 크롤링 디버깅의 중요성

**실제 문제 상황**:
1. ❌ CSS 셀렉터가 안 맞음
2. ❌ 네트워크 오류 (타임아웃)
3. ❌ 데이터가 None
4. ❌ 빈 리스트 반환

**→ 디버깅 없이는 원인 파악 불가능!**

---

### 🐛 디버깅 코드 추가

```python
import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

st.title("📰 네이버 뉴스 헤드라인 크롤러 (디버깅 버전)")

category = st.selectbox(
    "뉴스 카테고리",
    ["정치", "경제", "사회", "생활/문화", "IT/과학"]
)

category_code = {
    "정치": "100",
    "경제": "101",
    "사회": "102",
    "생활/문화": "103",
    "IT/과학": "105"
}

if st.button("뉴스 수집하기"):
    # 🔍 디버깅: URL 확인
    url = f"https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1={category_code[category]}"
    st.write(f"🔍 DEBUG - 요청 URL: {url}")

    # 🔍 디버깅: 네트워크 요청 시작
    st.write("🔍 DEBUG - HTTP 요청 시작...")
    start_time = time.time()

    try:
        response = requests.get(url, timeout=10)

        # 🔍 디버깅: 응답 상태 확인
        elapsed = time.time() - start_time
        st.write(f"🔍 DEBUG - 응답 코드: {response.status_code}")
        st.write(f"🔍 DEBUG - 응답 시간: {elapsed:.2f}초")
        st.write(f"🔍 DEBUG - 응답 크기: {len(response.text):,}자")

        # 🔍 디버깅: HTML 일부 미리보기
        with st.expander("🔍 DEBUG - HTML 미리보기 (처음 500자)"):
            st.code(response.text[:500])

        # 성공 여부 확인
        if response.status_code == 200:
            st.write("✅ DEBUG - 요청 성공!")
        else:
            st.error(f"❌ DEBUG - 요청 실패: {response.status_code}")
            st.stop()

        # 🔍 디버깅: BeautifulSoup 파싱
        st.write("🔍 DEBUG - HTML 파싱 중...")
        soup = BeautifulSoup(response.text, 'html.parser')
        st.write(f"🔍 DEBUG - 파싱 완료: {type(soup)}")

        # 🔍 디버깅: CSS 셀렉터 테스트
        st.write("🔍 DEBUG - CSS 셀렉터로 뉴스 찾기...")
        headlines = soup.select('.sh_text')
        st.write(f"🔍 DEBUG - 찾은 뉴스 개수: {len(headlines)}개")

        # 빈 결과 처리
        if len(headlines) == 0:
            st.error("❌ DEBUG - 뉴스를 찾지 못했습니다! CSS 셀렉터 확인 필요")

            # 🔍 대안 셀렉터 시도
            st.write("🔍 DEBUG - 다른 셀렉터 시도...")
            alt_headlines = soup.select('.cluster_text_headline')
            st.write(f"🔍 DEBUG - 대안 셀렉터 결과: {len(alt_headlines)}개")

            if len(alt_headlines) > 0:
                headlines = alt_headlines
                st.success("✅ DEBUG - 대안 셀렉터로 발견!")
            else:
                st.stop()

        # 🔍 디버깅: 첫 번째 뉴스 상세 분석
        st.write("🔍 DEBUG - 첫 번째 뉴스 분석:")
        first_news = headlines[0]
        st.write(f"🔍 태그: {first_news.name}")
        st.write(f"🔍 클래스: {first_news.get('class')}")
        st.write(f"🔍 텍스트: {first_news.text.strip()}")
        st.write(f"🔍 href 속성: {first_news.get('href')}")

        # 데이터 추출
        news_list = []
        for idx, headline in enumerate(headlines[:10], 1):
            # 🔍 디버깅: 각 뉴스 처리
            title = headline.text.strip()
            link = headline.get('href')

            # None 체크
            if title and link:
                news_list.append({
                    "순번": idx,
                    "제목": title,
                    "링크": link
                })
                st.write(f"✅ DEBUG - {idx}번 뉴스 추출 성공")
            else:
                st.warning(f"⚠️ DEBUG - {idx}번 뉴스 데이터 누락 (title={title}, link={link})")

        # 🔍 디버깅: 최종 결과
        st.write(f"🔍 DEBUG - 최종 수집 개수: {len(news_list)}개")

        # 결과 표시
        st.success(f"✅ {len(news_list)}개 뉴스 수집 완료!")

        for news in news_list:
            st.write(f"**{news['순번']}. {news['제목']}**")
            st.write(f"🔗 {news['링크']}")
            st.divider()

        # CSV 저장
        if news_list:
            df = pd.DataFrame(news_list)
            csv = df.to_csv(index=False).encode('utf-8-sig')

            st.download_button(
                label="CSV 다운로드",
                data=csv,
                file_name=f"news_{category}.csv",
                mime="text/csv"
            )

    except requests.exceptions.Timeout:
        st.error("❌ DEBUG - 타임아웃! 네트워크 연결을 확인하세요.")
    except requests.exceptions.ConnectionError:
        st.error("❌ DEBUG - 연결 실패! 인터넷 연결을 확인하세요.")
    except Exception as e:
        st.error(f"❌ DEBUG - 예상치 못한 오류: {type(e).__name__}")
        st.exception(e)
```

---

### 🎯 디버깅 실습

**실험 1: CSS 셀렉터 오류 체험**
```python
# 🐛 잘못된 셀렉터
headlines = soup.select('.wrong_selector')
# → 빈 리스트 []

# 디버그 출력으로 원인 파악
st.write(f"찾은 개수: {len(headlines)}")  # 0개
```

**실험 2: 네트워크 타임아웃**
```python
# 🐛 매우 짧은 타임아웃 설정
response = requests.get(url, timeout=0.001)
# → Timeout 에러 발생
```

**실험 3: None 값 처리**
```python
# 🐛 속성이 없는 경우
link = headline.get('href')  # None일 수 있음!

# ✅ 올바른 처리
if link:
    news_list.append(...)
else:
    st.warning("링크 없음!")
```

---

### 🐛 실전 버그 수정

**버그 1: 빈 결과**
```python
# 문제: 뉴스가 0개
headlines = soup.select('.sh_text')
print(len(headlines))  # 0

# AI에게 질문
"CSS 셀렉터 .sh_text로 뉴스를 찾을 수 없어요.
웹 페이지 구조가 바뀐 것 같은데 어떻게 확인하나요?"

# 해결: 브라우저 개발자 도구로 확인
# 1. 네이버 뉴스 페이지 열기
# 2. F12 → Elements
# 3. 뉴스 제목 우클릭 → Inspect
# 4. 실제 클래스명 확인
```

**버그 2: 깨진 텍스트**
```python
# 🐛 잘못된 인코딩
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
# → 한글 깨짐

# ✅ 인코딩 명시
response.encoding = 'utf-8'
soup = BeautifulSoup(response.text, 'html.parser')
```

---

### 💡 배운 점 정리

**Q: CSS 셀렉터가 안 맞으면 어떻게 하나요?**
```
A: 1. 브라우저 개발자 도구로 실제 클래스명 확인
   2. 여러 셀렉터 시도 (대안 준비)
   3. 디버그 출력으로 원인 파악
```

**Q: 네트워크 오류는 어떻게 처리하나요?**
```
A: try-except로 예외 처리
   - Timeout: 타임아웃 시간 늘리기
   - ConnectionError: 인터넷 연결 확인
```

**Q: None 값은 왜 생기나요?**
```
A: HTML 요소에 속성이 없을 때
   .get() 메서드는 없으면 None 반환
   → if 문으로 체크 필수!
```

---

### 🎯 나의 언어로 정리하기 (파인만 기법)

> **왜 이 방법이 중요한가?**: 웹 크롤링은 여러 단계를 거치는 복잡한 프로세스입니다.
> 각 단계를 내 언어로 설명할 수 있어야 문제 발생 시 스스로 해결할 수 있습니다!

#### 📝 실습: 웹 크롤링 과정 설명해보기

**Step 1: 나만의 방식으로 써보기** (5분)

친구에게 설명한다고 생각하고 써보세요:
```
웹 크롤링이 어떻게 작동하는지 내가 이해한 내용:

"requests.get()으로 URL을 요청하면..."
"BeautifulSoup은..."
"CSS 셀렉터는..."

✍️ [여기에 자유롭게 작성]
```

**Step 2: AI와 검증하기** (5-10분)

💬 AI에게 이렇게 질문:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
웹 크롤링 과정에 대해 내가 이해한 내용이야:

"[위에서 작성한 내용을 여기에 복사-붙여넣기]"

이 설명이 정확해? 틀린 부분이나 빠진 개념 있어?
초보자가 이해하기 쉽게 비유도 들어줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**Step 3: 수정하고 재정리** (3분)

AI 피드백을 반영해서 다시 써보세요:
```
[수정된 설명]
```

---

#### 🎯 즉시 미션

다음 중 하나를 선택해서 "나의 언어로 설명하기":

**옵션 A**: `requests.get(url, timeout=10)`의 역할
```
내 설명: "이 코드는 웹 서버에..."
```

**옵션 B**: `BeautifulSoup(response.text, 'html.parser')`가 하는 일
```
내 설명: "BeautifulSoup은 HTML 문자열을..."
```

**옵션 C**: `soup.select('.sh_text')`의 작동 원리
```
내 설명: "CSS 셀렉터는..."
```

**옵션 D**: `try-except`로 네트워크 에러를 처리하는 이유
```
내 설명: "크롤링 중 에러가 발생할 수 있어서..."
```

---

#### 💡 학습 효과 비교

| 방법 | 이해도 | 문제해결력 | 실전 응용력 |
|------|--------|-----------|------------|
| 그냥 코드 복사하기 | 20% | 낮음 | 거의 없음 |
| 코드 실행하고 결과 보기 | 50% | 보통 | 낮음 |
| **나의 언어로 정리** | 85% | 높음 | 매우 높음 |

> 💡 **실전 팁**: 크롤링 에러가 나면 "어느 단계에서 문제가 생겼는지"를 설명해보세요.
> 내가 이해한 것을 설명하다 보면 문제가 어디인지 자연스럽게 발견됩니다!

---

## Step 4: 코드 이해하기 (30분)

### 🧩 크롤링 과정 분해

**1단계: HTTP 요청**
```python
response = requests.get(url)
# → 웹 서버에 페이지 요청
```

**2단계: HTML 파싱**
```python
soup = BeautifulSoup(response.text, 'html.parser')
# → HTML 문자열을 객체로 변환
```

**3단계: 데이터 추출**
```python
headlines = soup.select('.sh_text')
# → CSS 셀렉터로 원하는 요소 찾기
```

**4단계: 데이터 정리**
```python
title = headline.text.strip()
link = headline['href']
# → 텍스트와 속성 추출
```

---

### 🔍 CSS 셀렉터 배우기

**기본 선택자**:
```python
# 클래스 선택
soup.select('.sh_text')

# ID 선택
soup.select('')

# 태그 선택
soup.select('div')

# 복합 선택
soup.select('div.sh_text')
soup.select('div > a')
```

**브라우저에서 확인하는 법**:
```
1. 뉴스 페이지 열기
2. F12 → Elements 탭
3. 뉴스 제목에 마우스 오버
4. 우클릭 → Copy → Copy selector
5. 복사된 셀렉터 사용
```

---

## Step 5: 기능 추가하기 (40분)

### 🎨 개선 아이디어

**AI에게 요청해보세요**:

**1. 날짜/시간 표시**:
```
"수집한 뉴스의 날짜와 시간도 함께 표시해줘"
```

**2. 검색 기능**:
```
"수집한 뉴스 중에서 키워드로 검색할 수 있게 해줘"
```

**3. 여러 카테고리 동시 수집**:
```
"여러 카테고리를 선택해서 한 번에 수집하고
카테고리별로 구분해서 보여줘"
```

**4. 자동 수집 (선택)**:
```
"10분마다 자동으로 뉴스를 수집해서
새로운 뉴스가 있으면 알림을 주는 기능을 만들어줘"
```

---

### 💻 개선된 코드 예시

```python
import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime

st.title("📰 네이버 뉴스 크롤러 Pro")

# 여러 카테고리 선택
categories = st.multiselect(
    "뉴스 카테고리 (여러 개 선택 가능)",
    ["정치", "경제", "사회", "생활/문화", "IT/과학"],
    default=["정치"]
)

# 수집 개수 선택
count = st.slider("수집할 뉴스 개수", 5, 50, 10)

if st.button("뉴스 수집하기"):
    all_news = []

    for category in categories:
        with st.spinner(f"{category} 뉴스 수집 중..."):
            # ... 크롤링 코드 ...

            for news in news_list:
                news['카테고리'] = category
                news['수집시간'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                all_news.append(news)

    # 검색 기능
    search = st.text_input("🔍 뉴스 검색")
    if search:
        filtered = [n for n in all_news if search in n['제목']]
        st.write(f"검색 결과: {len(filtered)}개")
        for news in filtered:
            st.write(f"**[{news['카테고리']}] {news['제목']}**")
    else:
        for news in all_news:
            st.write(f"**[{news['카테고리']}] {news['제목']}**")
```

---

## Step 6: 네트워크로 공유하기 (15분)

### 🌐 크롤러 공유하기

**네트워크 공유 실행**:
```bash
streamlit run news_crawler.py --server.address 0.0.0.0
```

---

### 🎯 공유 미션

**2인 1조 활동** (15분):

**시나리오 1: 실시간 뉴스 모니터링**
1. A: 크롤러 공유, "정치" 카테고리 수집
2. B: A의 앱 접속, "경제" 카테고리 수집
3. 서로 결과 비교 (어떤 뉴스가 TOP인지)

**시나리오 2: 협업 데이터 수집**
1. A: 오전 뉴스 수집 → CSV 저장
2. B: 같은 카테고리 오후 뉴스 수집
3. 두 CSV 파일 비교 (어떤 뉴스가 사라졌는지)

**재미있는 실험**:
- 같은 뉴스를 1시간 간격으로 수집해서 순위 변화 관찰
- 여러 카테고리 뉴스 개수 비교

---

## Step 7: 나만의 뉴스 크롤러 만들기 (20분)

### 🎯 내가 관심 있는 뉴스 모으기

> **핵심 질문**: "어떤 뉴스가 **정말 궁금한가요?**"

**질문 1: 관심 분야는?**
```
예시:
- 스포츠 (좋아하는 팀 뉴스)
- 게임/IT (새로운 게임 소식)
- 연예 (좋아하는 아이돌)
- 과학 (우주, 환경 뉴스)

✍️ [내가 매일 확인하고 싶은 분야 적기]
```

**질문 2: 왜 이 뉴스가 필요한가요?**
```
내 관심사: "게임 뉴스"

이유:
- 새로운 게임 출시 소식 놓치고 싶지 않아서
- 게임 업데이트 정보를 빠르게 알고 싶어서
- 친구들과 대화 소재로 쓰고 싶어서

💭 [나만의 이유 생각해보기]
```

**질문 3: 어떻게 바꾸면 더 유용할까?**
```
추가하고 싶은 기능:
- 특정 키워드만 필터링 (예: "신작", "이벤트")
- 중요한 뉴스 알림
- 읽은 뉴스 체크

💭 [AI에게 어떻게 요청할지 생각]
```

---

### 🤖 AI와 함께 커스터마이징

> **💡 핵심 전략**: "게임 뉴스 크롤링해줘"는 너무 모호합니다.
> SETUP 구조로 **정확한 요구사항**을 전달하면 **즉시 사용 가능한 코드**를 받습니다!

---

#### 📋 1단계: 키워드 필터링 추가 (복사-붙여넣기 프롬프트)

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[SETUP]
- 상황: 현재 네이버 뉴스 크롤러가 있어요
- 목표: 특정 키워드가 포함된 뉴스만 필터링해서 보여주기
- 입력: 사용자가 키워드 입력 (예: "신작", "이벤트")
- 출력: 필터링된 뉴스 제목과 링크 목록
- 제약사항: requests, beautifulsoup4, streamlit 라이브러리만 사용
- 코드 스타일: 기존 코드 구조 유지, 주석은 한글로

[YOUR TASK]
현재 뉴스 크롤러에 다음 기능을 추가해줘:

1. **키워드 입력 위젯**
   - st.text_input()로 필터링할 키워드 입력
   - 기본값: 빈 문자열 (모든 뉴스 표시)
   - 플레이스홀더: "예: 신작, 이벤트"

2. **필터링 로직**
   - 입력한 키워드가 제목에 포함된 뉴스만 표시
   - 대소문자 구분 없이 검색
   - 키워드가 없으면 모든 뉴스 표시

3. **결과 표시**
   - 필터링된 뉴스 개수 표시
   - "총 15개 뉴스 중 3개가 '신작'을 포함합니다" 같은 메시지
   - 필터링된 결과 목록

현재 코드를 수정해서 완전한 코드를 보여줘.
주석으로 어떤 부분이 바뀌었는지 표시해줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**📌 복사 팁**: 위 박스 전체를 복사해서 AI(ChatGPT, Claude)에 붙여넣기!

---

#### 📋 2단계: 여러 사이트 크롤링 (복사-붙여넣기 프롬프트)

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[SETUP]
- 상황: 1단계 키워드 필터링 기능이 있는 크롤러예요
- 목표: 네이버 + 다음 뉴스를 동시에 크롤링하기
- 입력: 사이트 선택 체크박스 (네이버, 다음)
- 출력: 선택한 사이트들의 뉴스를 통합해서 표시
- 제약사항: requests, beautifulsoup4, streamlit, pandas 사용 가능
- 코드 스타일: 기존 키워드 필터링 기능 유지

[YOUR TASK]
1단계 코드에 다음 기능을 추가해줘:

1. **사이트 선택 위젯**
   - st.multiselect()로 크롤링할 사이트 선택
   - 옵션: ["네이버", "다음"]
   - 기본값: ["네이버"]

2. **다음 뉴스 크롤링 함수**
   - 네이버와 동일한 형태로 다음 뉴스 크롤링
   - URL: https://news.daum.net/breakingnews/digital
   - CSS 셀렉터: 'a.link_txt' (제목), 'a.link_txt' (링크)

3. **통합 결과 표시**
   - 선택한 사이트별로 탭 생성 (st.tabs())
   - 각 탭에 해당 사이트 뉴스 표시
   - 키워드 필터링은 모든 사이트에 적용

4. **에러 처리**
   - 특정 사이트 크롤링 실패 시 다른 사이트는 계속 진행
   - 실패한 사이트는 경고 메시지 표시

완전한 코드를 보여주고, 새로 추가된 부분에 # [NEW] 주석 표시해줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

---

#### 📋 3단계: 실전 응용 (나만의 용도 프롬프트 만들기)

**나만의 프롬프트 작성 템플릿**:
```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[SETUP]
- 상황: [내가 만든 뉴스 크롤러 설명]
- 목표: [구체적인 목표 - 예: 관심 분야 뉴스, 가격 모니터링 등]
- 입력: [어떤 정보를 입력받을지]
- 출력: [어떤 형태로 결과를 보여줄지]
- 제약사항: [사용할 라이브러리, 제한사항]
- 코드 스타일: [원하는 스타일]

[YOUR TASK]
[구체적인 기능 요청 1]
[구체적인 기능 요청 2]
[구체적인 기능 요청 3]

완전한 코드를 보여주고, 주석으로 설명해줘.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

**💡 실전 예시 - 게임 출시 모니터링 앱**:
```
[SETUP]
- 상황: 뉴스 크롤러가 있어요
- 목표: 게임 신작 출시 소식을 자동으로 모아서 보여주기
- 입력: 관심 게임 장르 선택 (RPG, FPS, 시뮬레이션 등)
- 출력: 신작 게임 뉴스 + 출시일 정보 표시
- 제약사항: requests, beautifulsoup4, streamlit, datetime 사용
- 코드 스타일: 주석 한글, 변수명 영어

[YOUR TASK]
게임 신작 모니터링 크롤러를 만들어줘:

1. 크롤링 대상 설정
   - 네이버 게임 뉴스: https://entertain.naver.com/section/105
   - 다음 게임 뉴스: https://news.daum.net/breakingnews/entertain/game

2. 장르 필터링 기능
   - st.selectbox()로 장르 선택 (RPG, FPS, 시뮬레이션, 어드벤처, 전체)
   - 선택한 장르가 제목에 포함된 뉴스만 표시

3. 신작 키워드 하이라이트
   - "신작", "출시", "사전예약" 등 주요 키워드 강조
   - st.markdown()으로 **굵게** 표시

4. 시간순 정렬
   - 최신 뉴스가 위에 오도록 정렬
   - 크롤링 시각 표시

완전한 코드를 보여주고, 각 부분에 설명 주석 추가해줘.
특히 CSS 셀렉터 부분은 상세히 설명해줘.
```

---

#### ✅ AI 응답 검증 체크리스트

AI가 준 코드를 실행하기 전에 확인:
- [ ] 필요한 라이브러리가 모두 import 되었나요?
- [ ] CSS 셀렉터가 올바르게 작성되었나요?
- [ ] 네트워크 에러 처리(try-except)가 있나요?
- [ ] 타임아웃 설정이 있나요? (timeout=10)
- [ ] 내가 요청한 필터링 기능이 모두 포함되었나요?

**크롤링이 안 될 때 이렇게 물어보세요**:
```
"위 코드가 작동하지 않아. 다음 정보를 확인해줘:
1. CSS 셀렉터 '.sh_text'가 최신 네이버 뉴스 페이지에서 맞는지
2. User-Agent 헤더가 필요한지
3. 타임아웃을 더 길게 설정해야 하는지

수정된 코드와 함께 왜 안 됐는지 설명해줘."
```

---

### 💡 추천 커스터마이징 아이디어

**레벨 1: 간단 (10분)**
```
- 뉴스 개수 제한 조절
- 제목 길이 제한 (너무 길면 생략)
- 수집 시간 표시
```

**레벨 2: 보통 (15분)**
```
- 키워드 필터링 (입력한 단어 포함 뉴스만)
- 제외 키워드 (특정 단어 제외)
- 읽은 뉴스 표시 (체크박스)
```

**레벨 3: 도전 (20분+)**
```
- 여러 사이트 뉴스 동시 수집
- 뉴스 요약 (AI API 활용)
- 알림 기능 (새 뉴스 생기면 알림)
```

---

### ✅ 완성 체크

**질문**:
- [ ] 내 관심 분야 뉴스를 수집하나요?
- [ ] 필요한 뉴스만 골라내나요?
- [ ] 매일 사용하고 싶나요?
- [ ] 다른 사람에게 유용함을 설명할 수 있나요?

**중요**:
```
💡 "과제로 만든 크롤러"가 아니라
   "내가 매일 쓰는 뉴스 모으미"가 되었나요?
```

---

# 🎯 오늘의 마무리 (16:30-17:00)

## 완성 체크리스트

### ✅ QR 코드 생성기
- [ ] URL/텍스트 입력 가능
- [ ] QR 코드 이미지 생성
- [ ] 이미지 다운로드 가능
- [ ] 색상/크기 변경 (선택)

### ✅ 뉴스 크롤러
- [ ] 네이버 뉴스 수집 가능
- [ ] 카테고리 선택 가능
- [ ] 제목과 링크 표시
- [ ] CSV 저장 가능
- [ ] 에러 처리 포함

---

## 배운 것 정리

### 🎓 오늘 배운 핵심 개념

**1. 파일 처리**:
- BytesIO로 메모리 내 파일 처리
- 이미지 생성 및 다운로드
- CSV 파일 저장

**2. 웹 크롤링**:
- HTTP 요청 (requests)
- HTML 파싱 (BeautifulSoup)
- CSS 셀렉터
- 에러 처리 (try-except)

**3. 디버깅**:
- 네트워크 상태 확인
- CSS 셀렉터 검증
- None 값 처리
- 에러 메시지 분석

---

### 💡 주요 라이브러리

```python
# QR 코드 생성
import qrcode
from io import BytesIO

# 웹 크롤링
import requests
from bs4 import BeautifulSoup

# 데이터 처리
import pandas as pd
```

---

## 과제 (선택)

> **💡 과제 선택 철학**:
> "23개 중 무조건 1개 선택"이 아닙니다.
> "오늘 배운 것을 **내 문제 해결**에 어떻게 쓸까?" 질문부터 시작하세요!

### 📋 과제 선택 가이드

**Step 1: 내 상황 생각하기** (1분)
```
오늘 배운 QR 코드 / 웹 크롤링으로 무엇을 하고 싶나요?

✅ QR 코드가 필요한 순간:
- SNS 공유, 명함, 와이파이 공유, 행사 초대

✅ 웹 크롤링이 필요한 순간:
- 특정 정보를 매일 확인, 가격 비교, 데이터 수집
```

**Step 2: 아래 카테고리에서 1개 선택** (2분)
```
1️⃣ QR 코드 기본 (5개) - QR 생성 연습
2️⃣ QR 코드 응용 (4개) - 실생활 활용
3️⃣ 크롤링 기본 (4개) - 웹 데이터 수집
4️⃣ 크롤링 응용 (5개) - 다른 사이트 크롤링
5️⃣ 통합 프로젝트 (3개) - QR + 크롤링 결합
6️⃣ 도전 과제 (3개) - 심화 학습

총 24개 옵션!
```

**Step 3: AI에게 구체적으로 요청** (30분+)
```
선택한 과제를 AI에게 이렇게 요청:

"오늘 만든 [QR 코드 생성기 / 뉴스 크롤러]를 다음과 같이 수정해줘:
1. [구체적인 기능 설명]
2. [사용할 라이브러리나 방법]
3. [예상되는 결과물]

기존 코드를 수정해서 보여줘."
```

---

### 1️⃣ QR 코드 기본 연습 (5개)

#### 과제 1-1: 디지털 명함 QR 코드
```
📱 내 정보를 담은 QR 코드 만들기

만들 것:
- 이름, 전화번호, 이메일, SNS 링크
- vCard 형식으로 생성
- 스캔하면 연락처에 바로 저장

💬 AI 프롬프트:
"QR 코드 생성기를 vCard 형식으로 변환해줘.
입력: 이름, 전화번호, 이메일, 인스타그램
출력: 스캔하면 연락처 앱에 자동 추가되는 QR 코드"

⏱️ 예상 시간: 20분
```

#### 과제 1-2: WiFi 공유 QR 코드
```
📶 손님용 와이파이 QR 코드

만들 것:
- WiFi SSID, 비밀번호 입력
- WiFi 정보가 담긴 QR 코드 생성
- 스캔하면 자동 연결

💬 AI 프롬프트:
"WiFi 정보 QR 코드를 만들어줘.
형식: WIFI:T:WPA;S:[SSID];P:[비밀번호];;
스캔하면 자동으로 연결되게 해줘."

⏱️ 예상 시간: 25분
```

#### 과제 1-3: QR 코드 배치 생성기
```
🎫 여러 개 QR 코드 한 번에 생성

만들 것:
- CSV 파일 업로드 (URL, 이름 목록)
- 각 항목마다 QR 코드 생성
- ZIP 파일로 다운로드

💬 AI 프롬프트:
"CSV 파일을 업로드하면 각 행의 URL로 QR 코드를 생성하고
모두 ZIP 파일로 다운로드하는 기능을 추가해줘.
pandas와 zipfile 라이브러리 사용."

⏱️ 예상 시간: 35분
```

#### 과제 1-4: QR 코드 색상 테마
```
🎨 브랜드 색상으로 QR 코드 꾸미기

만들 것:
- 여러 가지 색상 프리셋 (Instagram, YouTube, 기업 색상)
- 클릭하면 해당 색상으로 즉시 변경
- 미리보기 기능

💬 AI 프롬프트:
"QR 코드 색상 프리셋을 추가해줘.
- Instagram: 분홍색 그라데이션
- YouTube: 빨간색
- Naver: 초록색
버튼 클릭하면 fill_color와 back_color 자동 변경"

⏱️ 예상 시간: 30분
```

#### 과제 1-5: QR 코드 크기별 출력
```
📐 용도별 크기 자동 조절

만들 것:
- 명함용 (5x5cm), 포스터용 (15x15cm), 배너용 (30x30cm)
- 버튼 클릭하면 해당 크기로 생성
- 실제 인쇄 크기 표시

💬 AI 프롬프트:
"용도별 버튼을 추가하고 클릭하면 해당 용도에 맞는
box_size와 border로 QR 코드 생성해줘.
명함용: 작게, 포스터용: 크게"

⏱️ 예상 시간: 25분
```

---

### 2️⃣ QR 코드 실생활 응용 (4개)

#### 과제 2-1: 이벤트 초대장 QR
```
🎉 행사 초대 QR 코드 + 설명

만들 것:
- 행사 정보 입력 (제목, 날짜, 장소)
- QR 코드 + 텍스트 설명 이미지 생성
- 카카오톡/인스타 공유용 이미지

💬 AI 프롬프트:
"QR 코드 아래에 행사 제목, 날짜, 장소를 텍스트로 추가한
이미지를 생성해줘. Pillow의 ImageDraw 사용."

⏱️ 예상 시간: 40분
```

#### 과제 2-2: 메뉴판 QR 코드
```
🍽️ 레스토랑 메뉴 QR 코드

만들 것:
- 메뉴 정보 입력 (구글 폼 / 노션 페이지 URL)
- 테이블 번호별 QR 코드 생성
- "메뉴 보기" 텍스트 포함

💬 AI 프롬프트:
"테이블 번호를 입력하면 각 테이블용 QR 코드를 생성해줘.
URL 뒤에 ?table=1, ?table=2 파라미터 추가."

⏱️ 예상 시간: 30분
```

#### 과제 2-3: 단축 URL + QR 코드
```
🔗 긴 URL → 단축 URL → QR 코드

만들 것:
- bitly API 연동
- 긴 URL 입력하면 단축 URL 생성
- 단축 URL로 QR 코드 생성

💬 AI 프롬프트:
"bitly API를 사용해서 입력한 URL을 단축하고
단축된 URL로 QR 코드를 생성하는 기능을 추가해줘."

⏱️ 예상 시간: 45분
💡 참고: bitly API 키 필요 (무료)
```

#### 과제 2-4: QR 코드 스캔 추적
```
📊 QR 코드 스캔 횟수 추적

만들 것:
- Google Forms/TypeForm URL 생성
- QR 코드 스캔하면 자동 기록
- 간단한 통계 표시

💬 AI 프롬프트:
"QR 코드가 몇 번 스캔되었는지 추적하려면
어떤 서비스를 사용하면 좋을지 알려주고
간단한 예제 코드를 만들어줘."

⏱️ 예상 시간: 50분
💡 참고: 외부 서비스(bit.ly, QR Code Generator Pro) 필요
```

---

### 3️⃣ 웹 크롤링 기본 (4개)

#### 과제 3-1: 날씨 정보 크롤링
```
☀️ 네이버 날씨 정보 수집

만들 것:
- 지역별 날씨 크롤링
- 현재 기온, 날씨 상태, 미세먼지
- 간단한 대시보드 표시

💬 AI 프롬프트:
"네이버 날씨 페이지에서 서울의 현재 기온,
날씨 상태, 미세먼지 농도를 크롤링해서
Streamlit에 카드 형식으로 표시해줘."

⏱️ 예상 시간: 30분
```

#### 과제 3-2: 환율 정보 크롤링
```
💱 실시간 환율 수집

만들 것:
- 네이버 금융 환율 크롤링
- 달러, 엔화, 유로 환율
- 표와 그래프로 시각화

💬 AI 프롬프트:
"네이버 금융에서 USD, JPY, EUR 환율을 크롤링하고
표로 정리해줘. 어제 대비 변동률도 표시."

⏱️ 예상 시간: 35분
```

#### 과제 3-3: 인기 검색어 크롤링
```
🔥 실시간 인기 검색어

만들 것:
- 네이버 실시간 검색어 크롤링
- TOP 10 리스트 표시
- 5분마다 자동 갱신 (선택)

💬 AI 프롬프트:
"네이버 또는 다음의 실시간 검색어 TOP 10을 크롤링하고
순위와 함께 표시해줘. 각 검색어에 검색 링크도 추가."

⏱️ 예상 시간: 35분
```

#### 과제 3-4: 영화 정보 크롤링
```
🎬 현재 상영 영화 정보

만들 것:
- 네이버 영화 박스오피스 크롤링
- 영화 제목, 순위, 예매율
- CSV 저장 및 표시

💬 AI 프롬프트:
"네이버 영화 박스오피스에서 TOP 10 영화의
제목, 순위, 예매율, 개봉일을 크롤링해서
데이터프레임으로 보여줘."

⏱️ 예상 시간: 40분
```

---

### 4️⃣ 웹 크롤링 실전 응용 (5개)

#### 과제 4-1: 부동산 매물 모니터링
```
🏠 직방/다방 매물 정보 수집

만들 것:
- 특정 지역 원룸 매물 크롤링
- 가격, 위치, 면적 정보
- 가격 필터링 기능

💬 AI 프롬프트:
"직방 또는 네이버 부동산에서 [지역명]의
월세 매물을 크롤링해서 가격순으로 정렬해줘.
예산 필터(상한가) 기능도 추가."

⏱️ 예상 시간: 50분
⚠️ 주의: 크롤링 빈도 제한, robots.txt 확인
```

#### 과제 4-2: 중고거래 가격 비교
```
🛒 당근마켓/중고나라 가격 비교

만들 것:
- 검색어 입력 (예: "아이패드")
- 여러 사이트 가격 크롤링
- 최저가/평균가 분석

💬 AI 프롬프트:
"[검색어]로 당근마켓을 검색해서
매물 제목, 가격, 링크를 크롤링하고
가격 분포를 히스토그램으로 그려줘."

⏱️ 예상 시간: 55분
⚠️ 주의: 사이트별 정책 확인
```

#### 과제 4-3: 취업 공고 모니터링
```
💼 원티드/사람인 채용공고 수집

만들 것:
- 직무 키워드 입력 (예: "데이터 분석")
- 신규 공고 크롤링
- 마감일 임박 공고 강조

💬 AI 프롬프트:
"[직무명]으로 원티드 채용 공고를 크롤링하고
회사명, 포지션, 마감일을 표로 정리해줘.
마감일 7일 이내는 빨간색으로 표시."

⏱️ 예상 시간: 60분
```

#### 과제 4-4: YouTube 인기 영상 분석
```
📺 유튜브 인기 영상 정보

만들 것:
- 특정 채널의 최신 영상 크롤링
- 제목, 조회수, 좋아요 수
- 인기도 분석 그래프

💬 AI 프롬프트:
"YouTube Data API를 사용해서
[채널명]의 최근 영상 10개의 제목, 조회수, 좋아요를
가져와서 표와 차트로 보여줘."

⏱️ 예상 시간: 55분
💡 참고: YouTube Data API 키 필요 (무료)
```

#### 과제 4-5: 블로그 포스팅 키워드 분석
```
📝 네이버 블로그 트렌드 분석

만들 것:
- 검색어의 블로그 글 크롤링
- 많이 나오는 키워드 추출
- 워드 클라우드 시각화

💬 AI 프롬프트:
"[검색어]로 네이버 블로그를 검색하고
본문에서 명사를 추출해서 빈도수 TOP 20을
워드 클라우드로 만들어줘. konlpy 사용."

⏱️ 예상 시간: 70분
💡 참고: konlpy, wordcloud 라이브러리 필요
```

---

### 5️⃣ 통합 프로젝트 (QR + 크롤링) (3개)

#### 과제 5-1: 실시간 뉴스 QR 코드
```
📰 오늘의 TOP 뉴스 → QR 코드

만들 것:
1. 뉴스 헤드라인 크롤링
2. 각 뉴스 링크로 QR 코드 생성
3. 뉴스 제목 + QR 코드 이미지 생성

💬 AI 프롬프트:
"뉴스 TOP 5를 크롤링하고, 각 뉴스마다
제목과 QR 코드가 포함된 이미지를 생성해줘.
PIL로 텍스트와 QR 코드를 합성."

⏱️ 예상 시간: 60분
```

#### 과제 5-2: 맛집 리스트 QR 카드
```
🍴 맛집 검색 → QR 코드 명함

만들 것:
1. 지역 맛집 정보 크롤링 (네이버 플레이스)
2. 각 맛집 정보 카드 생성 (이름, 주소, 전화번호)
3. 카드마다 지도 링크 QR 코드 추가

💬 AI 프롬프트:
"[지역명] 맛집 TOP 10을 크롤링하고
각 맛집마다 이름, 주소, 평점, 네이버 지도 QR 코드를
포함한 카드 이미지를 생성해줘."

⏱️ 예상 시간: 70분
```

#### 과제 5-3: 이벤트 자동 초대장
```
🎊 온라인 이벤트 → 자동 초대장

만들 것:
1. 참가자 명단 CSV 업로드
2. 각 참가자별 초대 링크 생성 (파라미터 추가)
3. 개인별 QR 코드 초대장 이미지 생성
4. ZIP 파일로 다운로드

💬 AI 프롬프트:
"CSV 파일(이름, 이메일)을 업로드하면
각 참가자마다 고유 QR 코드가 포함된
초대장 이미지를 생성하고 ZIP으로 묶어줘.
URL에 ?name=[이름] 파라미터 추가."

⏱️ 예상 시간: 90분
```

---

### 6️⃣ 도전 과제 (심화) (3개)

#### 과제 6-1: 가격 변동 알림봇
```
🔔 관심 상품 가격 추적

만들 것:
1. 쿠팡/네이버쇼핑 상품 가격 크롤링
2. 일정 시간마다 가격 체크 (10분)
3. 가격 하락 시 알림 (콘솔 출력 or 이메일)

💬 AI 프롬프트:
"[상품 URL]의 가격을 10분마다 크롤링하고
이전 가격보다 낮아지면 '가격 하락!' 메시지를
출력하는 프로그램을 만들어줘.
APScheduler 또는 time.sleep 사용."

⏱️ 예상 시간: 90분
⚠️ 주의: 과도한 요청 금지 (time.sleep 필수)
```

#### 과제 6-2: QR 코드 로고 삽입
```
🎨 브랜드 로고가 있는 QR 코드

만들 것:
1. QR 코드 중앙에 로고 이미지 삽입
2. 로고 크기 자동 조절 (QR 코드의 25% 이내)
3. 스캔 가능 여부 확인

💬 AI 프롬프트:
"QR 코드를 생성한 후, 중앙에 업로드한 로고 이미지를
25% 크기로 삽입해줘. Pillow의 paste() 사용.
로고는 원형으로 크롭."

⏱️ 예상 시간: 75분
💡 참고: QR 코드 오류 정정 레벨 H로 설정 필요
```

#### 과제 6-3: 여러 사이트 동시 크롤링
```
🌐 멀티 크롤러

만들 것:
1. 네이버, 다음, 구글 뉴스 동시 크롤링
2. 각 사이트별 결과를 탭으로 구분
3. 공통 키워드 분석 (3곳 모두 나온 단어)

💬 AI 프롬프트:
"네이버, 다음, 구글 뉴스 TOP 10을 동시에 크롤링하고
st.tabs()로 사이트별 결과를 구분해서 보여줘.
세 사이트 모두에서 나온 공통 키워드도 추출."

⏱️ 예상 시간: 100분
⚠️ 주의: 각 사이트별 robots.txt 확인
```

---

### ✅ 과제 완성 후 체크리스트

**스스로 확인하기**:
- [ ] AI 프롬프트를 구체적으로 작성했나요?
- [ ] 코드가 실제로 작동하나요?
- [ ] 에러가 나면 디버깅 했나요?
- [ ] 실생활에서 사용할 수 있나요?
- [ ] 다른 사람에게 설명할 수 있나요?

**추가 도전**:
```
완성한 과제를 다음 단계로:
1. 친구/가족에게 공유하기
2. GitHub에 올리기 (포트폴리오)
3. 블로그에 과정 정리하기
```

---

### 💡 과제 선택 Tip

**고민된다면**:
```
1. "지금 당장 필요한 것" 선택
   예: 명함 필요 → QR 코드 명함 만들기

2. "취업 포트폴리오" 고려
   예: 웹 크롤링 + 데이터 분석 → 블로그 트렌드 분석

3. "재미있는 것" 우선
   예: 좋아하는 YouTube 채널 분석
```

**시간 부족하면**:
```
기본 과제 (1️⃣, 3️⃣)부터 시작
→ 30분 이내 완성 가능
→ 기초 탄탄히 다지기
```

---

## 다음 시간 예고 (3일차)

### 📅 3일차: AI 슈퍼파워 앱 만들기

**만들 프로그램**:
1. **실시간 날씨 앱** - OpenWeatherMap API
2. **AI 챗봇** - OpenAI/Claude API

**필요한 것**:
- API 키 (강사님이 준비)
- 오늘 배운 requests 라이브러리 활용

---

## 질문 시간

**자주 나오는 질문**:

**Q: 크롤링이 불법인가요?**
```
A: 개인 학습 목적은 OK
   상업적 이용은 사이트 정책 확인 필수
   robots.txt 확인하기
```

**Q: CSS 셀렉터를 어떻게 찾나요?**
```
A: 브라우저 F12 → Elements → 우클릭 → Copy selector
```

**Q: 웹 페이지 구조가 바뀌면 어떻게 하나요?**
```
A: 1. 셀렉터 다시 확인
   2. 코드 수정
   3. 대안 셀렉터 여러 개 준비
```

---

**수고하셨습니다! 🎉**

내일은 더 멋진 AI 앱을 만들어봅시다!
